{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ParlAI Tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwlw2022/nlp-chatbot-project/blob/main/Copy_of_ParlAI_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsb-Cvf6lnVX"
      },
      "source": [
        "<img src=\"https://parl.ai/docs/_static/img/parlai.png\" width=\"700\"/>\n",
        "\n",
        "**Author**: Stephen Roller ([GitHub](https://github.com/stephenroller), [Twitter](https://twitter.com/stephenroller))\n",
        "\n",
        "\n",
        "# Welcome to the ParlAI interactive tutorial\n",
        "\n",
        "In this tutorial we will:\n",
        "\n",
        "- Chat with a neural network model!\n",
        "- Show how to use common commands in ParlAI, like inspecting data and model outputs.\n",
        "- See where to find information about many options.\n",
        "- Show how to fine-tune a pretrained model on a specific task\n",
        "- Add our own datasets to ParlAI\n",
        "- And add our own models to ParlAI\n",
        "\n",
        "We won't be running any examples of using Amazon Mechanical Turk, or connecting to Chat services, but you can check out our [docs](https://parl.ai/docs/) for more information on these areas.\n",
        "\n",
        "**Note:** *Make sure you're running this session with a GPU attached.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bFnOWslsj9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3479fbcf-f2b0-4a9a-ab77-10a1f04c2d48"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  1 00:41:04 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMxd1KIRl9Xm"
      },
      "source": [
        "## Installing parlai\n",
        "\n",
        "We need to install ParlAI. Since we're in Google Colab, we can assume PyTorch and similar dependencies are installed already"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93Mn_I7MOEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c0ce93-f20b-4cc0-99cd-94022b7ea1f1"
      },
      "source": [
        "!pip install -q parlai\n",
        "!pip install -q subword_nmt # extra requirement we need for this tutorial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3MB 18.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 57.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.2MB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7MB 53.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 60.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.5MB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 56.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 55.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 46.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 59.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 12.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 58.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 56.1MB/s \n",
            "\u001b[?25h  Building wheel for websocket-server (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: omegaconf 2.0.6 has requirement PyYAML>=5.1.*, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fvcore 0.1.5.post20210423 has requirement pyyaml>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtVz5dCUmFkN"
      },
      "source": [
        "# Chatting with a model\n",
        "\n",
        "Let's start by chatting interactively with a model file from our model zoo! We'll pick our \"tutorial transformer generator\" model, which is a generative transformer trained on pushshift.io Reddit. You can take a look at the [model zoo](https://parl.ai/docs/zoo.html) for a more complete list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRJGRtMKmIWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9daada8d-422b-497f-db2e-e3e4605ab65b"
      },
      "source": [
        "# Import the Interactive script\n",
        "from parlai.scripts.interactive import Interactive\n",
        "\n",
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:tutorial_transformer_generator/model'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:43:16 | building data: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/tutorial_transformer_generator_v1.tar.gz\n",
            "00:43:16 | Downloading http://parl.ai/downloads/_models/tutorial_transformer_generator/tutorial_transformer_generator_v1.tar.gz to /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/tutorial_transformer_generator_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading tutorial_transformer_generator_v1.tar.gz: 100%|██████████| 1.12G/1.12G [00:49<00:00, 22.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:44:25 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model (previously: /checkpoint/roller/20190909/cleanreddit/585/model)\u001b[0m\n",
            "00:44:25 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
            "00:44:25 | Using CUDA\n",
            "00:44:25 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "00:44:25 | num words = 54944\n",
            "00:44:25 | TransformerGenerator: full interactive mode on.\n",
            "00:44:26 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "00:44:37 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "00:44:37 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "00:44:38 | Opt:\n",
            "00:44:38 |     activation: gelu\n",
            "00:44:38 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "00:44:38 |     adam_eps: 1e-06\n",
            "00:44:38 |     add_p1_after_newln: False\n",
            "00:44:38 |     aggregate_micro: False\n",
            "00:44:38 |     allow_missing_init_opts: False\n",
            "00:44:38 |     attention_dropout: 0.0\n",
            "00:44:38 |     batch_length_range: 5\n",
            "00:44:38 |     batch_sort_cache_type: pop\n",
            "00:44:38 |     batch_sort_field: text\n",
            "00:44:38 |     batchsize: 48\n",
            "00:44:38 |     beam_block_full_context: False\n",
            "00:44:38 |     beam_block_list_filename: None\n",
            "00:44:38 |     beam_block_ngram: 3\n",
            "00:44:38 |     beam_context_block_ngram: 3\n",
            "00:44:38 |     beam_delay: 30\n",
            "00:44:38 |     beam_length_penalty: 0.65\n",
            "00:44:38 |     beam_min_length: 10\n",
            "00:44:38 |     beam_min_n_best: 3\n",
            "00:44:38 |     beam_size: 8\n",
            "00:44:38 |     betas: '[0.9, 0.98]'\n",
            "00:44:38 |     bpe_add_prefix_space: None\n",
            "00:44:38 |     bpe_debug: False\n",
            "00:44:38 |     bpe_dropout: None\n",
            "00:44:38 |     bpe_merge: None\n",
            "00:44:38 |     bpe_vocab: None\n",
            "00:44:38 |     compute_tokenized_bleu: False\n",
            "00:44:38 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:44:38 |     datatype: train:stream\n",
            "00:44:38 |     delimiter: '\\n'\n",
            "00:44:38 |     dict_build_first: True\n",
            "00:44:38 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "00:44:38 |     dict_endtoken: __end__\n",
            "00:44:38 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "00:44:38 |     dict_include_test: False\n",
            "00:44:38 |     dict_include_valid: False\n",
            "00:44:38 |     dict_initpath: None\n",
            "00:44:38 |     dict_language: english\n",
            "00:44:38 |     dict_loaded: True\n",
            "00:44:38 |     dict_lower: True\n",
            "00:44:38 |     dict_max_ngram_size: -1\n",
            "00:44:38 |     dict_maxexs: -1\n",
            "00:44:38 |     dict_maxtokens: -1\n",
            "00:44:38 |     dict_minfreq: 0\n",
            "00:44:38 |     dict_nulltoken: __null__\n",
            "00:44:38 |     dict_starttoken: __start__\n",
            "00:44:38 |     dict_textfields: text,labels\n",
            "00:44:38 |     dict_tokenizer: bpe\n",
            "00:44:38 |     dict_unktoken: __unk__\n",
            "00:44:38 |     display_add_fields: \n",
            "00:44:38 |     display_examples: False\n",
            "00:44:38 |     display_prettify: False\n",
            "00:44:38 |     distributed_world_size: 64\n",
            "00:44:38 |     download_path: None\n",
            "00:44:38 |     dropout: 0.1\n",
            "00:44:38 |     dynamic_batching: None\n",
            "00:44:38 |     embedding_projection: random\n",
            "00:44:38 |     embedding_size: 512\n",
            "00:44:38 |     embedding_type: random\n",
            "00:44:38 |     embeddings_scale: True\n",
            "00:44:38 |     eval_batchsize: None\n",
            "00:44:38 |     evaltask: None\n",
            "00:44:38 |     ffn_size: 2048\n",
            "00:44:38 |     force_fp16_tokens: True\n",
            "00:44:38 |     fp16: True\n",
            "00:44:38 |     fp16_impl: safe\n",
            "00:44:38 |     gpu: 0\n",
            "00:44:38 |     gradient_clip: 10.0\n",
            "00:44:38 |     hide_labels: False\n",
            "00:44:38 |     history_add_global_end_token: None\n",
            "00:44:38 |     history_reversed: False\n",
            "00:44:38 |     history_size: -1\n",
            "00:44:38 |     image_cropsize: 224\n",
            "00:44:38 |     image_mode: raw\n",
            "00:44:38 |     image_size: 256\n",
            "00:44:38 |     inference: beam\n",
            "00:44:38 |     init_model: None\n",
            "00:44:38 |     init_opt: None\n",
            "00:44:38 |     interactive_mode: True\n",
            "00:44:38 |     interactive_task: True\n",
            "00:44:38 |     invsqrt_lr_decay_gamma: -1\n",
            "00:44:38 |     is_debug: False\n",
            "00:44:38 |     label_truncate: 128\n",
            "00:44:38 |     learn_positional_embeddings: True\n",
            "00:44:38 |     learningrate: 0.0005\n",
            "00:44:38 |     local_human_candidates_file: None\n",
            "00:44:38 |     log_every_n_secs: 30.0\n",
            "00:44:38 |     log_keep_fields: all\n",
            "00:44:38 |     loglevel: info\n",
            "00:44:38 |     lr_scheduler: invsqrt\n",
            "00:44:38 |     lr_scheduler_decay: 0.5\n",
            "00:44:38 |     lr_scheduler_patience: 3\n",
            "00:44:38 |     max_train_time: -1\n",
            "00:44:38 |     metrics: default\n",
            "00:44:38 |     model: transformer/generator\n",
            "00:44:38 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "00:44:38 |     model_parallel: False\n",
            "00:44:38 |     momentum: 0\n",
            "00:44:38 |     multitask_weights: [1]\n",
            "00:44:38 |     n_decoder_layers: -1\n",
            "00:44:38 |     n_encoder_layers: -1\n",
            "00:44:38 |     n_heads: 16\n",
            "00:44:38 |     n_layers: 8\n",
            "00:44:38 |     n_positions: 512\n",
            "00:44:38 |     n_segments: 0\n",
            "00:44:38 |     nesterov: True\n",
            "00:44:38 |     no_cuda: False\n",
            "00:44:38 |     num_epochs: 5.0\n",
            "00:44:38 |     numthreads: 1\n",
            "00:44:38 |     numworkers: 4\n",
            "00:44:38 |     nus: [0.7]\n",
            "00:44:38 |     optimizer: fused_adam\n",
            "00:44:38 |     outfile: \n",
            "00:44:38 |     output_scaling: 1.0\n",
            "00:44:38 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model'}\"\n",
            "00:44:38 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:44:38 |     person_tokens: False\n",
            "00:44:38 |     port: 61337\n",
            "00:44:38 |     pytorch_context_length: -1\n",
            "00:44:38 |     pytorch_datapath: None\n",
            "00:44:38 |     pytorch_include_labels: True\n",
            "00:44:38 |     pytorch_preprocess: False\n",
            "00:44:38 |     pytorch_teacher_batch_sort: False\n",
            "00:44:38 |     pytorch_teacher_dataset: None\n",
            "00:44:38 |     pytorch_teacher_task: None\n",
            "00:44:38 |     rank_candidates: False\n",
            "00:44:38 |     relu_dropout: 0.0\n",
            "00:44:38 |     save_after_valid: True\n",
            "00:44:38 |     save_every_n_secs: -1\n",
            "00:44:38 |     save_format: conversations\n",
            "00:44:38 |     share_word_embeddings: True\n",
            "00:44:38 |     short_final_eval: True\n",
            "00:44:38 |     show_advanced_args: False\n",
            "00:44:38 |     shuffle: False\n",
            "00:44:38 |     single_turn: False\n",
            "00:44:38 |     skip_generation: False\n",
            "00:44:38 |     special_tok_lst: None\n",
            "00:44:38 |     split_lines: False\n",
            "00:44:38 |     starttime: May01_00-44\n",
            "00:44:38 |     task: internal:new_reddit:presorted\n",
            "00:44:38 |     temperature: 1.0\n",
            "00:44:38 |     tensorboard_log: False\n",
            "00:44:38 |     text_truncate: 512\n",
            "00:44:38 |     topk: 10\n",
            "00:44:38 |     topp: 0.9\n",
            "00:44:38 |     truncate: -1\n",
            "00:44:38 |     update_freq: 1\n",
            "00:44:38 |     use_reply: label\n",
            "00:44:38 |     validation_cutoff: 1.0\n",
            "00:44:38 |     validation_every_n_epochs: -1\n",
            "00:44:38 |     validation_every_n_secs: 1800.0\n",
            "00:44:38 |     validation_max_exs: 9920\n",
            "00:44:38 |     validation_metric: ppl\n",
            "00:44:38 |     validation_metric_mode: min\n",
            "00:44:38 |     validation_patience: 0\n",
            "00:44:38 |     validation_share_agent: False\n",
            "00:44:38 |     variant: xlm\n",
            "00:44:38 |     verbose: False\n",
            "00:44:38 |     warmup_rate: 0.0001\n",
            "00:44:38 |     warmup_updates: 20000\n",
            "00:44:38 |     weight_decay: 0.01\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "00:44:39 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m hello world\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1m+ / u / dogetipbot 10 doge\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mit ' s a bot that ' s been around for a while .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m oh cool\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi ' m glad you like it . : )\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m DONE\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1myou ' re the best shibe i ' ve ever met .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [DONE]\n",
            "CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hfUEgovmWay"
      },
      "source": [
        "The same on the command line:\n",
        "```bash\n",
        "python -m parlai.scripts.interactive --model-file zoo:tutorial_transformer_generator/model\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_hGrZGGmaWF"
      },
      "source": [
        "# Taking a look at some data\n",
        "\n",
        "We can look at look into a specific dataset. Let's look into the \"empathetic dialogues\" dataset, which aims to teach models how to respond with text expressing the appropriate emotion. We have over existing 80 datasets in ParlAI. You can take a full look in our [task list](https://parl.ai/docs/tasks.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqckSXqlmWuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d646f52-f488-4812-8e53-66d7470991ea"
      },
      "source": [
        "# The display_data script is used to show the contents of a particular task.\n",
        "# By default, we show the train\n",
        "from parlai.scripts.display_data import DisplayData\n",
        "DisplayData.main(task='personachat', num_examples=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:45:45 | Opt:\n",
            "00:45:45 |     allow_missing_init_opts: False\n",
            "00:45:45 |     batchsize: 1\n",
            "00:45:45 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:45:45 |     datatype: train:ordered\n",
            "00:45:45 |     dict_class: None\n",
            "00:45:45 |     display_add_fields: \n",
            "00:45:45 |     download_path: None\n",
            "00:45:45 |     dynamic_batching: None\n",
            "00:45:45 |     hide_labels: False\n",
            "00:45:45 |     ignore_agent_reply: True\n",
            "00:45:45 |     image_cropsize: 224\n",
            "00:45:45 |     image_mode: raw\n",
            "00:45:45 |     image_size: 256\n",
            "00:45:45 |     init_model: None\n",
            "00:45:45 |     init_opt: None\n",
            "00:45:45 |     is_debug: False\n",
            "00:45:45 |     loglevel: info\n",
            "00:45:45 |     max_display_len: 1000\n",
            "00:45:45 |     model: None\n",
            "00:45:45 |     model_file: None\n",
            "00:45:45 |     multitask_weights: [1]\n",
            "00:45:45 |     mutators: None\n",
            "00:45:45 |     num_examples: 5\n",
            "00:45:45 |     override: \"{'task': 'personachat', 'num_examples': 5}\"\n",
            "00:45:45 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:45:45 |     starttime: May01_00-45\n",
            "00:45:45 |     task: personachat\n",
            "00:45:45 |     verbose: False\n",
            "00:45:45 | creating task(s): personachat\n",
            "[building data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat]\n",
            "00:45:45 | Downloading http://parl.ai/downloads/personachat/personachat.tgz to /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading personachat.tgz: 100%|██████████| 223M/223M [00:19<00:00, 11.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:46:16 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i like to remodel homes.\n",
            "your persona: i like to go hunting.\n",
            "your persona: i like to shoot a bow.\n",
            "your persona: my favorite holiday is halloween.\n",
            "hi , how are you doing ? i am getting ready to do some cheetah chasing to stay in shape .\u001b[0;0m\n",
            "   \u001b[1;94myou must be very fast . hunting is one of my favorite hobbies .\u001b[0;0m\n",
            "\u001b[0mi am ! for my hobby i like to do canning or some whittling .\u001b[0;0m\n",
            "   \u001b[1;94mi also remodel homes when i am not out bow hunting .\u001b[0;0m\n",
            "\u001b[0mthat is neat . when i was in high school i placed 6th in 100m dash !\u001b[0;0m\n",
            "   \u001b[1;94mthat is awesome . do you have a favorite season or time of year ?\u001b[0;0m\n",
            "\u001b[0mi do not . but i do have a favorite meat since that is all i eat exclusively .\u001b[0;0m\n",
            "   \u001b[1;94mwhat is your favorite meat to eat ?\u001b[0;0m\n",
            "\u001b[0mi would have to say its prime rib . do you have any favorite foods ?\u001b[0;0m\n",
            "   \u001b[1;94mi like chicken or macaroni and cheese .\u001b[0;0m\n",
            "00:46:17 | loaded 8939 episodes with a total of 65719 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9C6oHq87zGx"
      },
      "source": [
        "The black, unindented text is the _prompt_, while the blue text is the _label_. That is, the label is what we will be training the model to mimic.\n",
        "\n",
        "We can also ask to see fewer examples, and get them from the validation set instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGNSBetWmfGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac74567-eef0-45ad-e622-7f300f68a9df"
      },
      "source": [
        "# we can instead ask to see fewer examples, and get them from the valid set.\n",
        "DisplayData.main(task='personachat', num_examples=3, datatype='valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:46:44 | Opt:\n",
            "00:46:44 |     allow_missing_init_opts: False\n",
            "00:46:44 |     batchsize: 1\n",
            "00:46:44 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:46:44 |     datatype: valid\n",
            "00:46:44 |     dict_class: None\n",
            "00:46:44 |     display_add_fields: \n",
            "00:46:44 |     download_path: None\n",
            "00:46:44 |     dynamic_batching: None\n",
            "00:46:44 |     hide_labels: False\n",
            "00:46:44 |     ignore_agent_reply: True\n",
            "00:46:44 |     image_cropsize: 224\n",
            "00:46:44 |     image_mode: raw\n",
            "00:46:44 |     image_size: 256\n",
            "00:46:44 |     init_model: None\n",
            "00:46:44 |     init_opt: None\n",
            "00:46:44 |     is_debug: False\n",
            "00:46:44 |     loglevel: info\n",
            "00:46:44 |     max_display_len: 1000\n",
            "00:46:44 |     model: None\n",
            "00:46:44 |     model_file: None\n",
            "00:46:44 |     multitask_weights: [1]\n",
            "00:46:44 |     mutators: None\n",
            "00:46:44 |     num_examples: 3\n",
            "00:46:44 |     override: \"{'task': 'personachat', 'num_examples': 3, 'datatype': 'valid'}\"\n",
            "00:46:44 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:46:44 |     starttime: May01_00-46\n",
            "00:46:44 |     task: personachat\n",
            "00:46:44 |     verbose: False\n",
            "00:46:44 | creating task(s): personachat\n",
            "00:46:44 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n",
            "\u001b[1;31m- - - NEW EPISODE: personachat - - -\u001b[0;0m\n",
            "\u001b[0myour persona: i read twenty books a year.\n",
            "your persona: i am a stunt double as my second job.\n",
            "your persona: i only eat kosher.\n",
            "your persona: i was raised in a single parent household.\n",
            "hello what are doing today ?\u001b[0;0m\n",
            "   \u001b[1;94mi am good , i just got off work and tired , i have two jobs .\u001b[0;0m\n",
            "\u001b[0mi just got done watching a horror movie\u001b[0;0m\n",
            "   \u001b[1;94mi rather read , i have read about 20 books this year .\u001b[0;0m\n",
            "\u001b[0mwow ! i do love a good horror movie . loving this cooler weather\u001b[0;0m\n",
            "   \u001b[1;94mbut a good movie is always good .\u001b[0;0m\n",
            "00:46:44 | loaded 1000 episodes with a total of 7801 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVSrgRrEmdS-"
      },
      "source": [
        "On the command line:\n",
        "```bash\n",
        "python -m parlai.scripts.display_data --task empathetic_dialogues\n",
        "```\n",
        "or a bit shorter\n",
        "```\n",
        "python -m parlai.scripts.display_data -t empathetic_dialogues\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_M8Zr86n2_G"
      },
      "source": [
        "# Training a model\n",
        "\n",
        "Well it's one thing looking at data, but what if we want to train our own model (from scratch)? Let's train a very simple seq2seq LSTM with attention, to respond to empathetic dialogues.\n",
        "\n",
        "To get some extra performance, we'll initialize using GloVe embeddings, but we will cap the training time to 2 minutes for this tutorial. It won't perform very well, but that's okay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBhVQycSn2q_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b693f4-e9c1-4d4c-a340-a9a19f30b7bd"
      },
      "source": [
        "# we'll save it in the \"from_scratch_model\" directory\n",
        "!rm -rf from_scratch_model\n",
        "!mkdir -p from_scratch_model\n",
        "\n",
        "from parlai.scripts.train_model import TrainModel\n",
        "TrainModel.main(\n",
        "    # we MUST provide a filename\n",
        "    model_file='from_scratch_model/model',\n",
        "    # train on empathetic dialogues\n",
        "    task='personachat',\n",
        "    # limit training time to 2 minutes, and a batchsize of 16\n",
        "    max_train_time=5 * 60,\n",
        "    batchsize=16,\n",
        "    \n",
        "    # we specify the model type as seq2seq\n",
        "    model='seq2seq',\n",
        "    # some hyperparamter choices. We'll use attention. We could use pretrained\n",
        "    # embeddings too, with embedding_type='fasttext', but they take a long\n",
        "    # time to download.\n",
        "    \n",
        "    # embedding_type='glove',\n",
        "    attention='dot',\n",
        "    # tie the word embeddings of the encoder/decoder/softmax.\n",
        "    lookuptable='all',\n",
        "    # truncate text and labels at 64 tokens, for memory and time savings\n",
        "    truncate=64,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:48:19 | building dictionary first...\n",
            "00:48:19 | Opt:\n",
            "00:48:19 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "00:48:19 |     adam_eps: 1e-08\n",
            "00:48:19 |     add_p1_after_newln: False\n",
            "00:48:19 |     aggregate_micro: False\n",
            "00:48:19 |     allow_missing_init_opts: False\n",
            "00:48:19 |     attention: dot\n",
            "00:48:19 |     attention_length: 48\n",
            "00:48:19 |     attention_time: post\n",
            "00:48:19 |     batchsize: 1\n",
            "00:48:19 |     beam_block_full_context: True\n",
            "00:48:19 |     beam_block_list_filename: None\n",
            "00:48:19 |     beam_block_ngram: -1\n",
            "00:48:19 |     beam_context_block_ngram: -1\n",
            "00:48:19 |     beam_delay: 30\n",
            "00:48:19 |     beam_length_penalty: 0.65\n",
            "00:48:19 |     beam_min_length: 1\n",
            "00:48:19 |     beam_size: 1\n",
            "00:48:19 |     betas: '(0.9, 0.999)'\n",
            "00:48:19 |     bidirectional: False\n",
            "00:48:19 |     bpe_add_prefix_space: None\n",
            "00:48:19 |     bpe_debug: False\n",
            "00:48:19 |     bpe_dropout: None\n",
            "00:48:19 |     bpe_merge: None\n",
            "00:48:19 |     bpe_vocab: None\n",
            "00:48:19 |     compute_tokenized_bleu: False\n",
            "00:48:19 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:48:19 |     datatype: train\n",
            "00:48:19 |     decoder: same\n",
            "00:48:19 |     delimiter: '\\n'\n",
            "00:48:19 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "00:48:19 |     dict_endtoken: __end__\n",
            "00:48:19 |     dict_file: from_scratch_model/model.dict\n",
            "00:48:19 |     dict_include_test: False\n",
            "00:48:19 |     dict_include_valid: False\n",
            "00:48:19 |     dict_initpath: None\n",
            "00:48:19 |     dict_language: english\n",
            "00:48:19 |     dict_loaded: False\n",
            "00:48:19 |     dict_lower: False\n",
            "00:48:19 |     dict_max_ngram_size: -1\n",
            "00:48:19 |     dict_maxexs: -1\n",
            "00:48:19 |     dict_maxtokens: -1\n",
            "00:48:19 |     dict_minfreq: 0\n",
            "00:48:19 |     dict_nulltoken: __null__\n",
            "00:48:19 |     dict_starttoken: __start__\n",
            "00:48:19 |     dict_textfields: text,labels\n",
            "00:48:19 |     dict_tokenizer: re\n",
            "00:48:19 |     dict_unktoken: __unk__\n",
            "00:48:19 |     display_examples: False\n",
            "00:48:19 |     download_path: None\n",
            "00:48:19 |     dropout: 0.1\n",
            "00:48:19 |     dynamic_batching: None\n",
            "00:48:19 |     embedding_projection: random\n",
            "00:48:19 |     embedding_type: random\n",
            "00:48:19 |     embeddingsize: 128\n",
            "00:48:19 |     eval_batchsize: None\n",
            "00:48:19 |     eval_dynamic_batching: None\n",
            "00:48:19 |     evaltask: None\n",
            "00:48:19 |     force_fp16_tokens: False\n",
            "00:48:19 |     fp16: False\n",
            "00:48:19 |     fp16_impl: safe\n",
            "00:48:19 |     gpu: -1\n",
            "00:48:19 |     gradient_clip: 0.1\n",
            "00:48:19 |     hiddensize: 128\n",
            "00:48:19 |     hide_labels: False\n",
            "00:48:19 |     history_add_global_end_token: None\n",
            "00:48:19 |     history_reversed: False\n",
            "00:48:19 |     history_size: -1\n",
            "00:48:19 |     image_cropsize: 224\n",
            "00:48:19 |     image_mode: no_image_model\n",
            "00:48:19 |     image_size: 256\n",
            "00:48:19 |     inference: greedy\n",
            "00:48:19 |     init_model: None\n",
            "00:48:19 |     init_opt: None\n",
            "00:48:19 |     input_dropout: 0.0\n",
            "00:48:19 |     interactive_mode: False\n",
            "00:48:19 |     invsqrt_lr_decay_gamma: -1\n",
            "00:48:19 |     is_debug: False\n",
            "00:48:19 |     label_truncate: None\n",
            "00:48:19 |     learningrate: 1\n",
            "00:48:19 |     load_from_checkpoint: True\n",
            "00:48:19 |     log_every_n_secs: -1\n",
            "00:48:19 |     log_every_n_steps: 50\n",
            "00:48:19 |     loglevel: info\n",
            "00:48:19 |     lookuptable: all\n",
            "00:48:19 |     lr_scheduler: reduceonplateau\n",
            "00:48:19 |     lr_scheduler_decay: 0.5\n",
            "00:48:19 |     lr_scheduler_patience: 3\n",
            "00:48:19 |     max_train_steps: -1\n",
            "00:48:19 |     max_train_time: 300.0\n",
            "00:48:19 |     metrics: default\n",
            "00:48:19 |     model: seq2seq\n",
            "00:48:19 |     model_file: from_scratch_model/model\n",
            "00:48:19 |     momentum: 0\n",
            "00:48:19 |     multitask_weights: [1]\n",
            "00:48:19 |     mutators: None\n",
            "00:48:19 |     nesterov: True\n",
            "00:48:19 |     no_cuda: False\n",
            "00:48:19 |     num_epochs: -1\n",
            "00:48:19 |     num_workers: 0\n",
            "00:48:19 |     numlayers: 2\n",
            "00:48:19 |     numsoftmax: 1\n",
            "00:48:19 |     nus: (0.7,)\n",
            "00:48:19 |     optimizer: sgd\n",
            "00:48:19 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'personachat', 'max_train_time': 300.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n",
            "00:48:19 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:48:19 |     person_tokens: False\n",
            "00:48:19 |     rank_candidates: False\n",
            "00:48:19 |     rnn_class: lstm\n",
            "00:48:19 |     save_after_valid: False\n",
            "00:48:19 |     save_every_n_secs: -1\n",
            "00:48:19 |     short_final_eval: False\n",
            "00:48:19 |     skip_generation: False\n",
            "00:48:19 |     special_tok_lst: None\n",
            "00:48:19 |     split_lines: False\n",
            "00:48:19 |     starttime: May01_00-48\n",
            "00:48:19 |     task: personachat\n",
            "00:48:19 |     temperature: 1.0\n",
            "00:48:19 |     tensorboard_log: False\n",
            "00:48:19 |     tensorboard_logdir: None\n",
            "00:48:19 |     text_truncate: None\n",
            "00:48:19 |     topk: 10\n",
            "00:48:19 |     topp: 0.9\n",
            "00:48:19 |     truncate: 64\n",
            "00:48:19 |     update_freq: 1\n",
            "00:48:19 |     use_reply: label\n",
            "00:48:19 |     validation_cutoff: 1.0\n",
            "00:48:19 |     validation_every_n_epochs: -1\n",
            "00:48:19 |     validation_every_n_secs: -1\n",
            "00:48:19 |     validation_every_n_steps: -1\n",
            "00:48:19 |     validation_max_exs: -1\n",
            "00:48:19 |     validation_metric: accuracy\n",
            "00:48:19 |     validation_metric_mode: None\n",
            "00:48:19 |     validation_patience: 10\n",
            "00:48:19 |     validation_share_agent: False\n",
            "00:48:19 |     verbose: False\n",
            "00:48:19 |     wandb_entity: None\n",
            "00:48:19 |     wandb_log: False\n",
            "00:48:19 |     wandb_name: None\n",
            "00:48:19 |     wandb_project: None\n",
            "00:48:19 |     warmup_rate: 0.0001\n",
            "00:48:19 |     warmup_updates: -1\n",
            "00:48:19 |     weight_decay: None\n",
            "00:48:20 | creating task(s): personachat\n",
            "00:48:20 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rBuilding dictionary:   0%|          | 0.00/65.7k [00:00<?, ?ex/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:48:20 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building dictionary: 100%|██████████| 65.7k/65.7k [00:03<00:00, 16.6kex/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:48:24 | Saving dictionary to from_scratch_model/model.dict\n",
            "00:48:24 | dictionary built with 18745 tokens in 0.0s\n",
            "00:48:24 | No model with opt yet at: from_scratch_model/model(.opt)\n",
            "00:48:24 | Using CUDA\n",
            "00:48:24 | loading dictionary from from_scratch_model/model.dict\n",
            "00:48:24 | num words = 18745\n",
            "00:48:24 | Total parameters: 2,979,257 (2,979,257 trainable)\n",
            "00:48:24 | Opt:\n",
            "00:48:24 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "00:48:24 |     adam_eps: 1e-08\n",
            "00:48:24 |     add_p1_after_newln: False\n",
            "00:48:24 |     aggregate_micro: False\n",
            "00:48:24 |     allow_missing_init_opts: False\n",
            "00:48:24 |     attention: dot\n",
            "00:48:24 |     attention_length: 48\n",
            "00:48:24 |     attention_time: post\n",
            "00:48:24 |     batchsize: 16\n",
            "00:48:24 |     beam_block_full_context: True\n",
            "00:48:24 |     beam_block_list_filename: None\n",
            "00:48:24 |     beam_block_ngram: -1\n",
            "00:48:24 |     beam_context_block_ngram: -1\n",
            "00:48:24 |     beam_delay: 30\n",
            "00:48:24 |     beam_length_penalty: 0.65\n",
            "00:48:24 |     beam_min_length: 1\n",
            "00:48:24 |     beam_size: 1\n",
            "00:48:24 |     betas: '(0.9, 0.999)'\n",
            "00:48:24 |     bidirectional: False\n",
            "00:48:24 |     bpe_add_prefix_space: None\n",
            "00:48:24 |     bpe_debug: False\n",
            "00:48:24 |     bpe_dropout: None\n",
            "00:48:24 |     bpe_merge: None\n",
            "00:48:24 |     bpe_vocab: None\n",
            "00:48:24 |     compute_tokenized_bleu: False\n",
            "00:48:24 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:48:24 |     datatype: train\n",
            "00:48:24 |     decoder: same\n",
            "00:48:24 |     delimiter: '\\n'\n",
            "00:48:24 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "00:48:24 |     dict_endtoken: __end__\n",
            "00:48:24 |     dict_file: from_scratch_model/model.dict\n",
            "00:48:24 |     dict_include_test: False\n",
            "00:48:24 |     dict_include_valid: False\n",
            "00:48:24 |     dict_initpath: None\n",
            "00:48:24 |     dict_language: english\n",
            "00:48:24 |     dict_loaded: True\n",
            "00:48:24 |     dict_lower: False\n",
            "00:48:24 |     dict_max_ngram_size: -1\n",
            "00:48:24 |     dict_maxexs: -1\n",
            "00:48:24 |     dict_maxtokens: -1\n",
            "00:48:24 |     dict_minfreq: 0\n",
            "00:48:24 |     dict_nulltoken: __null__\n",
            "00:48:24 |     dict_starttoken: __start__\n",
            "00:48:24 |     dict_textfields: text,labels\n",
            "00:48:24 |     dict_tokenizer: re\n",
            "00:48:24 |     dict_unktoken: __unk__\n",
            "00:48:24 |     display_examples: False\n",
            "00:48:24 |     download_path: None\n",
            "00:48:24 |     dropout: 0.1\n",
            "00:48:24 |     dynamic_batching: None\n",
            "00:48:24 |     embedding_projection: random\n",
            "00:48:24 |     embedding_type: random\n",
            "00:48:24 |     embeddingsize: 128\n",
            "00:48:25 |     eval_batchsize: None\n",
            "00:48:25 |     eval_dynamic_batching: None\n",
            "00:48:25 |     evaltask: None\n",
            "00:48:25 |     force_fp16_tokens: False\n",
            "00:48:25 |     fp16: False\n",
            "00:48:25 |     fp16_impl: safe\n",
            "00:48:25 |     gpu: -1\n",
            "00:48:25 |     gradient_clip: 0.1\n",
            "00:48:25 |     hiddensize: 128\n",
            "00:48:25 |     hide_labels: False\n",
            "00:48:25 |     history_add_global_end_token: None\n",
            "00:48:25 |     history_reversed: False\n",
            "00:48:25 |     history_size: -1\n",
            "00:48:25 |     image_cropsize: 224\n",
            "00:48:25 |     image_mode: raw\n",
            "00:48:25 |     image_size: 256\n",
            "00:48:25 |     inference: greedy\n",
            "00:48:25 |     init_model: None\n",
            "00:48:25 |     init_opt: None\n",
            "00:48:25 |     input_dropout: 0.0\n",
            "00:48:25 |     interactive_mode: False\n",
            "00:48:25 |     invsqrt_lr_decay_gamma: -1\n",
            "00:48:25 |     is_debug: False\n",
            "00:48:25 |     label_truncate: None\n",
            "00:48:25 |     learningrate: 1\n",
            "00:48:25 |     load_from_checkpoint: True\n",
            "00:48:25 |     log_every_n_secs: -1\n",
            "00:48:25 |     log_every_n_steps: 50\n",
            "00:48:25 |     loglevel: info\n",
            "00:48:25 |     lookuptable: all\n",
            "00:48:25 |     lr_scheduler: reduceonplateau\n",
            "00:48:25 |     lr_scheduler_decay: 0.5\n",
            "00:48:25 |     lr_scheduler_patience: 3\n",
            "00:48:25 |     max_train_steps: -1\n",
            "00:48:25 |     max_train_time: 300.0\n",
            "00:48:25 |     metrics: default\n",
            "00:48:25 |     model: seq2seq\n",
            "00:48:25 |     model_file: from_scratch_model/model\n",
            "00:48:25 |     momentum: 0\n",
            "00:48:25 |     multitask_weights: [1]\n",
            "00:48:25 |     mutators: None\n",
            "00:48:25 |     nesterov: True\n",
            "00:48:25 |     no_cuda: False\n",
            "00:48:25 |     num_epochs: -1\n",
            "00:48:25 |     num_workers: 0\n",
            "00:48:25 |     numlayers: 2\n",
            "00:48:25 |     numsoftmax: 1\n",
            "00:48:25 |     nus: (0.7,)\n",
            "00:48:25 |     optimizer: sgd\n",
            "00:48:25 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'personachat', 'max_train_time': 300.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n",
            "00:48:25 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:48:25 |     person_tokens: False\n",
            "00:48:25 |     rank_candidates: False\n",
            "00:48:25 |     rnn_class: lstm\n",
            "00:48:25 |     save_after_valid: False\n",
            "00:48:25 |     save_every_n_secs: -1\n",
            "00:48:25 |     short_final_eval: False\n",
            "00:48:25 |     skip_generation: False\n",
            "00:48:25 |     special_tok_lst: None\n",
            "00:48:25 |     split_lines: False\n",
            "00:48:25 |     starttime: May01_00-48\n",
            "00:48:25 |     task: personachat\n",
            "00:48:25 |     temperature: 1.0\n",
            "00:48:25 |     tensorboard_log: False\n",
            "00:48:25 |     tensorboard_logdir: None\n",
            "00:48:25 |     text_truncate: None\n",
            "00:48:25 |     topk: 10\n",
            "00:48:25 |     topp: 0.9\n",
            "00:48:25 |     truncate: 64\n",
            "00:48:25 |     update_freq: 1\n",
            "00:48:25 |     use_reply: label\n",
            "00:48:25 |     validation_cutoff: 1.0\n",
            "00:48:25 |     validation_every_n_epochs: -1\n",
            "00:48:25 |     validation_every_n_secs: -1\n",
            "00:48:25 |     validation_every_n_steps: -1\n",
            "00:48:25 |     validation_max_exs: -1\n",
            "00:48:25 |     validation_metric: accuracy\n",
            "00:48:25 |     validation_metric_mode: None\n",
            "00:48:25 |     validation_patience: 10\n",
            "00:48:25 |     validation_share_agent: False\n",
            "00:48:25 |     verbose: False\n",
            "00:48:25 |     wandb_entity: None\n",
            "00:48:25 |     wandb_log: False\n",
            "00:48:25 |     wandb_name: None\n",
            "00:48:25 |     wandb_project: None\n",
            "00:48:25 |     warmup_rate: 0.0001\n",
            "00:48:25 |     warmup_updates: -1\n",
            "00:48:25 |     weight_decay: None\n",
            "00:48:25 | creating task(s): personachat\n",
            "00:48:25 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n",
            "00:48:26 | training...\n",
            "00:48:28 | time:2s total_exs:800 total_steps:50 epochs:0.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   141.3     1  1009 23590   .8850      78.23 374.1  800  1.215   .02571 12.84  8.81   1 205.4  4805       0          0 6699   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "       .09219         0                   50 1214 28395 23.4\n",
            "\n",
            "00:48:30 | time:4s total_exs:1600 total_steps:100 epochs:0.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   147.8     1  1012 26427   .9100       84.6 417.9  800  1.185  .009301 13.13 8.337   1 210.1  5487       0          0 4175   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1212         0                  100 1222 31915 26.13\n",
            "\n",
            "00:48:32 | time:6s total_exs:2400 total_steps:150 epochs:0.04\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   145.3     1  1012 24933   .9062       82.1 394.2  800   1.23  .008973 12.54 8.116   1 200.7  4944       0          0 3346   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1307         0                  150 1213 29877 24.65\n",
            "\n",
            "00:48:34 | time:8s total_exs:3200 total_steps:200 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   146.3     1  1012 25743   .9075      83.06 407.1  800  1.242  .009027 13.03  8.01   1 208.5  5305       0          0 3011   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1400         0                  200 1220 31049 25.46\n",
            "\n",
            "00:48:36 | time:10s total_exs:4000 total_steps:250 epochs:0.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   141.3     1  1009 25420   .9050      78.22 402.9  800  1.265  .009044 13.22 7.797   1 211.6  5328       0          0 2433   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1617         0                  250 1221 30748 25.19\n",
            "\n",
            "00:48:38 | time:12s total_exs:4800 total_steps:300 epochs:0.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   144.7     1  1010 24072   .8975      81.65 381.5  800  1.309  .009028 12.88 7.666   1 206.2  4916       0          0 2135   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1687         0                  300 1216 28988 23.85\n",
            "\n",
            "00:48:40 | time:14s total_exs:5600 total_steps:350 epochs:0.09\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   143.9     1  1011 24170   .9113      80.68 382.5  800  1.286  .009003 13.15 7.584   1 210.4  5029       0          0 1966   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1747         0                  350 1221 29200 23.92\n",
            "\n",
            "00:48:42 | time:16s total_exs:6400 total_steps:400 epochs:0.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   146.8     1  1010 24541   .9012      83.65 388.9  800  1.355   .00932  12.9 7.413   1 206.5  5019       0          0 1657   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1890         0                  400 1216 29560 24.31\n",
            "\n",
            "00:48:44 | time:18s total_exs:7200 total_steps:450 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   150.4     1  1011 25644   .9012      87.23 405.9  800  1.324  .009312 13.11  7.34   1 209.7  5320       0          0 1541   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1866         0                  450 1220 30964 25.38\n",
            "\n",
            "00:48:46 | time:20s total_exs:8000 total_steps:500 epochs:0.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "     143     1  1009 26079   .9012      79.95 413.4  800  1.354  .009609 13.08 7.321   1 209.3  5408       0          0 1512   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1861         0                  500 1218 31487 25.85\n",
            "\n",
            "00:48:49 | time:22s total_exs:8800 total_steps:550 epochs:0.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "     140     1  1007 24170   .8862      77.06   384  800  1.378  .008996 12.65 7.229   1 202.4  4857       0          0 1379   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1885         0                  550 1209 29027 24.01\n",
            "\n",
            "00:48:51 | time:25s total_exs:9600 total_steps:600 epochs:0.15\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   147.5     1  1010 24759   .9113      84.44 392.3  800  1.379  .009972 13.11 7.112   1 209.7  5142       0          0 1226   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1974         0                  600 1219 29902 24.53\n",
            "\n",
            "00:48:53 | time:27s total_exs:10400 total_steps:650 epochs:0.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   142.3     1  1006 24909   .8875       79.4 396.3  800  1.323  .009649 13.21 7.115   1 211.3  5233       0          0 1231   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .1990         0                  650 1217 30143 24.78\n",
            "\n",
            "00:48:55 | time:29s total_exs:11200 total_steps:700 epochs:0.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   144.1     1  1008 25094   .9025      81.14 398.3  800  1.388  .008982 12.93 7.014   1 206.9  5151       0          0 1112   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2002         0                  700 1215 30245 24.9\n",
            "\n",
            "00:48:57 | time:31s total_exs:12000 total_steps:750 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.1     1  1004 24085   .8888      76.36 383.6  800  1.397  .009328  12.7 6.884   1 203.2  4872       0          0 976.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2055         0                  750 1208 28958 23.99\n",
            "\n",
            "00:48:59 | time:33s total_exs:12800 total_steps:800 epochs:0.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.6     1  1009 24968   .8988      78.59 396.1  800  1.372  .009344  12.9 6.839   1 206.5  5111       0          0 933.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2117         0                  800 1215 30080 24.78\n",
            "\n",
            "00:49:01 | time:35s total_exs:13600 total_steps:850 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.7     1  1009 25116   .9012      80.64 398.1  800  1.413  .009017 12.76 6.874   1 204.1  5080       0          0 967.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2008         0                  850 1214 30196 24.89\n",
            "\n",
            "00:49:03 | time:37s total_exs:14400 total_steps:900 epochs:0.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.3     1  1010 25441   .9012      82.16 403.1  800  1.365  .009634 13.44  6.81   1   215  5418       0          0 906.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2110         0                  900 1225 30860 25.21\n",
            "\n",
            "00:49:05 | time:39s total_exs:15200 total_steps:950 epochs:0.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.9     1  1009 25848   .8988      79.88 409.9  800  1.403  .009987 12.53 6.748   1 200.5  5138       0          0 852.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2125         0                  950 1209 30986 25.63\n",
            "\n",
            "00:49:07 | time:41s total_exs:16000 total_steps:1000 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   151.3     1  1012 24660   .9187      88.07 389.8  800  1.386   .01029 13.65 6.726   1 218.5  5323       0          0 833.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2009         0                 1000 1231 29983 24.37\n",
            "\n",
            "00:49:09 | time:43s total_exs:16800 total_steps:1050 epochs:0.26\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   146.7     1  1011 25587   .9038      83.45 404.8  800  1.397   .01061  13.1 6.748   1 209.7  5304       0          0  852   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2081         0                 1050 1221 30891 25.31\n",
            "\n",
            "00:49:11 | time:45s total_exs:17600 total_steps:1100 epochs:0.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.1     1  1010 25704   .8988      79.98 407.1  800  1.422  .009287    13 6.594   1 208.1  5294       0          0 730.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2250         0                 1100 1218 30999 25.46\n",
            "\n",
            "00:49:13 | time:47s total_exs:18400 total_steps:1150 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.5     1  1009 25486   .8888      79.47 404.1  800  1.442  .009651 12.64 6.499   1 202.2  5108       0          0 664.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2240         0                 1150 1211 30595 25.27\n",
            "\n",
            "00:49:15 | time:49s total_exs:19200 total_steps:1200 epochs:0.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.5     1  1011 25163   .9062      83.25 398.1  800  1.442  .009361 12.71 6.604   1 203.4  5060       0          0 737.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2161         0                 1200 1215 30223 24.89\n",
            "\n",
            "00:49:17 | time:51s total_exs:20000 total_steps:1250 epochs:0.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.9     1  1010 25310   .9012      80.84 401.1  800  1.454   .01027 12.79 6.629   1 204.6  5129       0          0 756.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2113         0                 1250 1214 30440 25.08\n",
            "\n",
            "00:49:19 | time:53s total_exs:20800 total_steps:1300 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.9     1  1011 25697   .9012      81.64 406.3  800  1.467   .01029 12.57 6.519   1 201.2  5111       0          0 677.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2235         0                 1300 1213 30809 25.41\n",
            "\n",
            "00:49:21 | time:55s total_exs:21600 total_steps:1350 epochs:0.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.2     1  1012 26722   .9062         81 422.6  800  1.431  .009343 12.68 6.534   1 202.9  5359       0          0 688.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2178         0                 1350 1215 32081 26.42\n",
            "\n",
            "00:49:23 | time:57s total_exs:22400 total_steps:1400 epochs:0.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.5     1  1010 26837   .9038      80.39 425.2  800   1.44  .009313 12.74 6.538   1 203.9  5419       0          0 690.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2217         0                 1400 1214 32256 26.59\n",
            "\n",
            "00:49:25 | time:59s total_exs:23200 total_steps:1450 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.6     1  1010 26703   .8925      78.52 423.2  800  1.464  .009004 12.62 6.427   1 201.9  5341       0          0 618.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2237         0                 1450 1211 32044 26.46\n",
            "\n",
            "00:49:26 | time:60s total_exs:24000 total_steps:1500 epochs:0.37\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.7     1  1008 26419   .8950       81.7 419.2  800  1.414  .009047 13.06 6.409   1   209  5477       0          0 607.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2309         0                 1500 1217 31896 26.21\n",
            "\n",
            "00:49:28 | time:62s total_exs:24800 total_steps:1550 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   144.1     1  1010 25721   .8975      81.02 407.5  800  1.467   .01025 12.81 6.335   1   205  5222       0          0  564   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2328         0                 1550 1215 30943 25.48\n",
            "\n",
            "00:49:30 | time:64s total_exs:25600 total_steps:1600 epochs:0.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.1     1  1008 26159   .8975      82.05 415.1  800  1.446  .009326 13.04 6.414   1 208.6  5412       0          0 610.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2280         0                 1600 1217 31572 25.95\n",
            "\n",
            "00:49:32 | time:66s total_exs:26400 total_steps:1650 epochs:0.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   148.4     1  1010 26114   .8962      85.26 413.8  800  1.467  .009633 12.96 6.405   1 207.3  5362       0          0 604.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2307         0                 1650 1217 31476 25.87\n",
            "\n",
            "00:49:34 | time:68s total_exs:27200 total_steps:1700 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.8     1  1008 26191   .9025      82.74 415.6  800  1.443  .009313 12.96 6.337   1 207.3  5385       0          0 564.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2251         0                 1700 1216 31577 25.99\n",
            "\n",
            "00:49:36 | time:70s total_exs:28000 total_steps:1750 epochs:0.43\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.1     1  1009 26084   .9000      82.01 413.5  800  1.442  .009346 13.17 6.327   1 210.7  5445       0          0 559.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2303         0                 1750 1220 31530 25.85\n",
            "\n",
            "00:49:38 | time:72s total_exs:28800 total_steps:1800 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.8     1  1010 26601   .8975      78.66 421.4  800   1.44   .00935 12.66 6.257   1 202.6  5336       0          0 521.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2338         0                 1800 1213 31937 26.35\n",
            "\n",
            "00:49:40 | time:74s total_exs:29600 total_steps:1850 epochs:0.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   145.1     1  1009 26662   .8975      82.06 422.8  800  1.479  .009053 12.67 6.282   1 202.8  5359       0          0  535   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2326         0                 1850 1212 32021 26.44\n",
            "\n",
            "00:49:42 | time:76s total_exs:30400 total_steps:1900 epochs:0.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.6     1  1010 25992   .9012      83.42 411.7  800  1.484   .01027 12.79  6.28   1 204.7  5266       0          0 533.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2305         0                 1900 1215 31258 25.74\n",
            "\n",
            "00:49:44 | time:78s total_exs:31200 total_steps:1950 epochs:0.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.2     1  1009 25797   .8938      79.14 409.2  800  1.496   .01025 12.84  6.25   1 205.4  5254       0          0 518.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2383         0                 1950 1214 31051 25.58\n",
            "\n",
            "00:49:46 | time:80s total_exs:32000 total_steps:2000 epochs:0.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     143     1  1010 25947   .8938      79.84 411.1  800  1.475  .009335  12.9 6.199   1 206.4  5303       0          0 492.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2352         0                 2000 1216 31250 25.71\n",
            "\n",
            "00:49:48 | time:82s total_exs:32800 total_steps:2050 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.9     1  1009 25826   .9050      81.77 409.3  800  1.467  .009955 12.95 6.127   1 207.2  5301       0          0 458.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2458         0                 2050 1217 31127 25.59\n",
            "\n",
            "00:49:50 | time:84s total_exs:33600 total_steps:2100 epochs:0.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.4     1  1009 25832   .8988      81.32 409.7  800   1.41   .00937 13.11 6.158   1 209.8  5372       0          0 472.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2460         0                 2100 1219 31204 25.62\n",
            "\n",
            "00:49:52 | time:86s total_exs:34400 total_steps:2150 epochs:0.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   147.3     1  1011 26141   .9050      84.08 413.8  800  1.414  .009327 13.42 6.188   1 214.8  5554       0          0 487.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2343         0                 2150 1226 31695 25.87\n",
            "\n",
            "00:49:54 | time:88s total_exs:35200 total_steps:2200 epochs:0.54\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.9     1  1008 24748   .8950      82.87 392.9  800  1.461   .01094 13.29  6.16   1 212.7  5224       0          0 473.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2421         0                 2200 1220 29972 24.56\n",
            "\n",
            "00:49:56 | time:90s total_exs:36000 total_steps:2250 epochs:0.55\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.1     1  1011 26145   .9075      81.94 413.8  800  1.465   .01027 13.03 6.173   1 208.5  5393       0          0 479.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2366         0                 2250 1219 31538 25.87\n",
            "\n",
            "00:49:58 | time:92s total_exs:36800 total_steps:2300 epochs:0.56\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.3     1  1010 26834   .8988      79.11 424.9  800  1.481  .009049 12.38 6.071   1 198.1  5260       0          0 433.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2409         0                 2300 1208 32094 26.57\n",
            "\n",
            "00:50:00 | time:94s total_exs:37600 total_steps:2350 epochs:0.57\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.2     1  1008 26019   .8950      80.19 412.9  800  1.462   .01093 13.04 6.079   1 208.6  5382       0          0 436.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2396         0                 2350 1217 31401 25.81\n",
            "\n",
            "00:50:02 | time:96s total_exs:38400 total_steps:2400 epochs:0.58\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   145.7     1  1008 25692   .8938      82.74 407.8  800   1.47  .009667 13.04 6.018   1 208.6  5317       0          0  411   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2522         0                 2400 1217 31009 25.5\n",
            "\n",
            "00:50:04 | time:98s total_exs:39200 total_steps:2450 epochs:0.60\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.3     1  1004 26207   .8825      76.54 417.5  800  1.475  .009377 12.97  6.16   1 207.6  5417       0          0 473.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2315         0                 2450 1212 31624 26.11\n",
            "\n",
            "00:50:06 | time:100s total_exs:40000 total_steps:2500 epochs:0.61\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.3     1  1008 26232   .8950      76.28 416.5  800  1.476   .00906 12.84  6.04   1 205.5  5349       0          0 420.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2461         0                 2500 1213 31581 26.04\n",
            "\n",
            "00:50:08 | time:101s total_exs:40800 total_steps:2550 epochs:0.62\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.8     1  1006 25849   .8938      80.86 410.9  800  1.507  .009609 12.84  5.96   1 205.5  5277       0          0 387.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2490         0                 2550 1212 31126 25.69\n",
            "\n",
            "00:50:10 | time:103s total_exs:41600 total_steps:2600 epochs:0.63\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.7     1  1011 25836   .9100      82.48 408.8  800  1.474  .009353 13.04 6.067   1 208.6  5330       0          0 431.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2440         0                 2600 1220 31166 25.56\n",
            "\n",
            "00:50:12 | time:105s total_exs:42400 total_steps:2650 epochs:0.65\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.4     1  1009 25599   .8925      82.37 406.1  800  1.463   .00937 13.34 6.025   1 213.4  5415       0          0 413.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2438         0                 2650 1222 31014 25.39\n",
            "\n",
            "00:50:13 | time:107s total_exs:43200 total_steps:2700 epochs:0.66\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.2     1  1011 25842   .9025      83.02 408.8  800  1.456  .009329 13.23 6.038   1 211.7  5409       0          0 418.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2479         0                 2700 1223 31251 25.56\n",
            "\n",
            "00:50:15 | time:109s total_exs:44000 total_steps:2750 epochs:0.67\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.4     1  1008 25925   .8975      80.43 411.6  800  1.484  .009071 12.79 5.885   1 204.6  5264       0          0 359.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2571         0                 2750 1212 31189 25.73\n",
            "\n",
            "00:50:17 | time:111s total_exs:44800 total_steps:2800 epochs:0.68\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   140.7     1  1011 26239   .8988      77.56 415.4  800  1.501  .009044 12.62 6.038   1   202  5243       0          0  419   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2454         0                 2800 1213 31483 25.97\n",
            "\n",
            "00:50:19 | time:113s total_exs:45600 total_steps:2850 epochs:0.69\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   149.7     1  1009 26312   .8988      86.65 417.2  800  1.468   .01026 13.16 5.936   1 210.5  5489       0          0 378.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2573         0                 2850 1220 31802 26.09\n",
            "\n",
            "00:50:21 | time:115s total_exs:46400 total_steps:2900 epochs:0.71\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   148.3     1  1011 25343   .9137      85.14 401.2  800  1.505  .009666 12.77 6.024   1 204.3  5124       0          0 413.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2446         0                 2900 1215 30467 25.08\n",
            "\n",
            "00:50:23 | time:117s total_exs:47200 total_steps:2950 epochs:0.72\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.6     1  1008 25853   .9062      78.59 410.2  800  1.487   .01157 12.65 5.999   1 202.4  5189       0          0 402.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2522         0                 2950 1211 31042 25.65\n",
            "\n",
            "00:50:25 | time:119s total_exs:48000 total_steps:3000 epochs:0.73\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.2     1  1008 25423   .8988      80.21 403.3  800  1.484  .009645 13.02 5.862   1 208.3  5251       0          0 351.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2626         0                 3000 1217 30675 25.22\n",
            "\n",
            "00:50:27 | time:121s total_exs:48800 total_steps:3050 epochs:0.74\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.3     1  1011 25367   .8975      81.14 401.3  800  1.488  .009688 13.18 6.011   1 210.9  5289       0          0 407.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2498         0                 3050 1222 30656 25.09\n",
            "\n",
            "00:50:29 | time:123s total_exs:49600 total_steps:3100 epochs:0.75\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.4     1  1012 25858   .9087      81.12 408.9  800  1.512  .009304 12.54  5.98   1 200.6  5127       0          0 395.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2464         0                 3100 1212 30985 25.56\n",
            "\n",
            "00:50:31 | time:125s total_exs:50400 total_steps:3150 epochs:0.77\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.3     1  1010 25489   .9087      81.17 403.7  800  1.485  .009672 12.98 5.995   1 207.7  5241       0          0 401.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2427         0                 3150 1218 30730 25.24\n",
            "\n",
            "00:50:33 | time:127s total_exs:51200 total_steps:3200 epochs:0.78\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   147.2     1  1010 25966   .9075      84.01 411.2  800  1.483  .009663 12.98 5.882   1 207.7  5338       0          0 358.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2439         0                 3200 1218 31304 25.71\n",
            "\n",
            "00:50:35 | time:129s total_exs:52000 total_steps:3250 epochs:0.79\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     145     1  1009 25560   .8950      81.94 405.4  800  1.478  .009029 12.68 5.923   1 202.9  5142       0          0 373.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2398         0                 3250 1212 30703 25.35\n",
            "\n",
            "00:50:37 | time:131s total_exs:52800 total_steps:3300 epochs:0.80\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.7     1  1011 26522   .9038      81.52 419.7  800  1.493  .009326 12.83 5.907   1 205.3  5385       0          0 367.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2445         0                 3300 1216 31907 26.24\n",
            "\n",
            "00:50:39 | time:133s total_exs:53600 total_steps:3350 epochs:0.82\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.3     1  1009 25603   .9012      81.18 405.9  800  1.499  .009368 12.85 5.891   1 205.6  5215       0          0 361.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2488         0                 3350 1215 30818 25.38\n",
            "\n",
            "00:50:41 | time:135s total_exs:54400 total_steps:3400 epochs:0.83\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   140.7     1  1007 25613   .8975      77.73   407  800  1.508  .009992 12.48 5.826   1 199.7  5081       0          0 339.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2589         0                 3400 1207 30694 25.45\n",
            "\n",
            "00:50:43 | time:137s total_exs:55200 total_steps:3450 epochs:0.84\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.2     1  1009 25725   .9000      83.06 407.7  800  1.474  .009377 13.09 5.912   1 209.4  5335       0          0 369.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2445         0                 3450 1219 31060 25.49\n",
            "\n",
            "00:50:45 | time:139s total_exs:56000 total_steps:3500 epochs:0.85\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     142     1  1008 25238   .8975         79 400.6  800  1.496   .01064  12.7 5.883   1 203.2  5088       0          0 358.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2437         0                 3500 1211 30326 25.05\n",
            "\n",
            "00:50:47 | time:141s total_exs:56800 total_steps:3550 epochs:0.86\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.2     1  1012 26077   .9062      81.95 412.3  800  1.507   .01026 12.82 5.839   1 205.1  5286       0          0 343.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2569         0                 3550 1217 31363 25.78\n",
            "\n",
            "00:50:49 | time:143s total_exs:57600 total_steps:3600 epochs:0.88\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.7     1  1009 26032   .9062      82.65 412.6  800  1.486  .009341 13.05 5.909   1 208.9  5387       0          0 368.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2491         0                 3600 1218 31419 25.8\n",
            "\n",
            "00:50:51 | time:145s total_exs:58400 total_steps:3650 epochs:0.89\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.4     1  1010 25903   .8925      83.34 410.5  800   1.45   .01028 13.51 5.874   1 216.1  5546       0          0 355.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2561         0                 3650 1226 31449 25.67\n",
            "\n",
            "00:50:53 | time:147s total_exs:59200 total_steps:3700 epochs:0.90\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.2     1  1009 26358   .9012      82.17 417.9  800  1.498  .009661 12.92 5.774   1 206.7  5400       0          0 321.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2564         0                 3700 1216 31759 26.13\n",
            "\n",
            "00:50:55 | time:149s total_exs:60000 total_steps:3750 epochs:0.91\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.4     1  1011 26427   .9113      80.26 418.2  800  1.524  .009348 12.69 5.843   1   203  5307       0          0 344.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2467         0                 3750 1214 31734 26.15\n",
            "\n",
            "00:50:57 | time:151s total_exs:60800 total_steps:3800 epochs:0.93\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   143.2     1  1009 26113   .8950      80.15 414.1  800  1.485  .009691 13.31 5.737   1 212.9  5510       0          0  310   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2586         0                 3800 1222 31623 25.89\n",
            "\n",
            "00:50:59 | time:153s total_exs:61600 total_steps:3850 epochs:0.94\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.3     1  1008 26198   .9000      81.31 415.8  800  1.498  .009403 12.88 5.824   1   206  5355       0          0 338.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2511         0                 3850 1214 31553   26\n",
            "\n",
            "00:51:01 | time:155s total_exs:62400 total_steps:3900 epochs:0.95\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     145     1  1009 26011   .9050      81.91 412.4  800  1.504   .00934    13 5.832   1   208  5361       0          0 341.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2536         0                 3900 1217 31372 25.79\n",
            "\n",
            "00:51:03 | time:157s total_exs:63200 total_steps:3950 epochs:0.96\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.8     1  1009 26234   .8900      78.71 416.1  800  1.521  .009684 12.57 5.713   1 201.2  5232       0          0 302.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2605         0                 3950 1210 31467 26.02\n",
            "\n",
            "00:51:05 | time:159s total_exs:64000 total_steps:4000 epochs:0.97\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.2     1  1009 25956   .8938      81.15 411.5  800  1.479  .009358 13.21 5.808   1 211.4  5438       0          0 332.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2548         0                 4000 1220 31394 25.73\n",
            "\n",
            "00:51:07 | time:161s total_exs:64800 total_steps:4050 epochs:0.99\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   147.9     1  1009 25691   .8962       84.8 407.3  800  1.484  .009359 13.14 5.877   1 210.3  5353       0          0 356.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2535         0                 4050 1220 31045 25.46\n",
            "\n",
            "00:51:09 | time:163s total_exs:65600 total_steps:4100 epochs:1.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.5     1  1008 25673   .8912      76.53 407.7  800  1.498  .009975 12.48 5.704   1 199.7  5089       0          0 300.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2570    .00125                 4100 1207 30762 25.49\n",
            "\n",
            "00:51:11 | time:164s total_exs:66400 total_steps:4150 epochs:1.01\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.9     1  1011 25883   .9087      82.71 409.7  800  1.478  .009644 13.21 5.799   1 211.3  5410       0          0 329.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2464         0                 4150 1222 31293 25.62\n",
            "\n",
            "00:51:13 | time:166s total_exs:67200 total_steps:4200 epochs:1.02\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.1     1  1006 25260   .8838      79.21 401.8  800  1.497  .009361 13.06 5.833   1 208.9  5247       0          0 341.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2418         0                 4200 1215 30507 25.12\n",
            "\n",
            "00:51:14 | time:168s total_exs:68000 total_steps:4250 epochs:1.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     144     1  1010 26229   .8938      80.88 415.4  800  1.499  .009351 13.03 5.786   1 208.5  5415       0          0 325.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2588         0                 4250 1219 31643 25.97\n",
            "\n",
            "00:51:17 | time:170s total_exs:68800 total_steps:4300 epochs:1.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.9     1  1009 25206   .8975      79.83 399.7  800  1.491  .009359 13.06 5.792   1   209  5221       0          0 327.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2528         0                 4300 1218 30427 24.99\n",
            "\n",
            "00:51:18 | time:172s total_exs:69600 total_steps:4350 epochs:1.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.5     1  1009 26407   .8988       81.4 418.7  800  1.507  .009975 13.01 5.647   1 208.1  5447       0          0 283.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2602         0                 4350 1217 31854 26.18\n",
            "\n",
            "00:51:20 | time:174s total_exs:70400 total_steps:4400 epochs:1.07\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     144     1  1009 25620   .8938      80.92 406.3  800  1.497   .01001 13.19 5.708   1 211.1  5360       0          0 301.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2500         0                 4400 1220 30980 25.4\n",
            "\n",
            "00:51:22 | time:176s total_exs:71200 total_steps:4450 epochs:1.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   140.4     1  1008 26262   .8912      77.34 416.7  800  1.524  .009331 12.76 5.744   1 204.1  5316       0          0 312.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2562         0                 4450 1212 31578 26.05\n",
            "\n",
            "00:51:24 | time:178s total_exs:72000 total_steps:4500 epochs:1.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.2     1  1008 26249   .8950      78.16 416.7  800  1.526   .00909 12.62 5.738   1   202  5261       0          0 310.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2517         0                 4500 1210 31510 26.05\n",
            "\n",
            "00:51:26 | time:180s total_exs:72800 total_steps:4550 epochs:1.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     147     1  1012 25767   .9100      83.78 407.4  800  1.513   .01035 13.25 5.704   1   212  5399       0          0 300.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2588         0                 4550 1224 31166 25.47\n",
            "\n",
            "00:51:28 | time:182s total_exs:73600 total_steps:4600 epochs:1.12\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.8     1  1008 26179   .8888      79.85 415.5  800  1.538  .009667 12.84  5.72   1 205.5  5337       0          0 304.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2504         0                 4600 1213 31517 25.98\n",
            "\n",
            "00:51:30 | time:184s total_exs:74400 total_steps:4650 epochs:1.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     144     1  1008 25670   .8962         81 407.3  800  1.501   .01029  13.2 5.748   1 211.1  5375       0          0 313.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2563         0                 4650 1220 31045 25.47\n",
            "\n",
            "00:51:32 | time:186s total_exs:75200 total_steps:4700 epochs:1.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.1     1  1009 25776   .9012      83.05 408.8  800  1.516  .009072 12.84 5.674   1 205.4  5249       0          0 291.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2571         0                 4700 1214 31025 25.56\n",
            "\n",
            "00:51:34 | time:188s total_exs:76000 total_steps:4750 epochs:1.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.6     1  1009 25589   .8975      82.54 405.9  800  1.495  .009703 13.11 5.749   1 209.7  5320       0          0 313.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2504         0                 4750 1218 30909 25.38\n",
            "\n",
            "00:51:36 | time:190s total_exs:76800 total_steps:4800 epochs:1.17\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.1     1  1009 26255   .9050      77.99 416.2  800  1.569  .009692 12.41 5.722   1 198.6  5165       0          0 305.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2504         0                 4800 1208 31421 26.02\n",
            "\n",
            "00:51:38 | time:192s total_exs:77600 total_steps:4850 epochs:1.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.3     1  1008 25649   .8975      83.29 407.2  800  1.474  .009397 13.47 5.731   1 215.5  5485       0          0 308.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2548         0                 4850 1223 31134 25.46\n",
            "\n",
            "00:51:40 | time:194s total_exs:78400 total_steps:4900 epochs:1.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.1     1  1010 26245   .8900      79.03 415.9  800  1.524   .00904 12.87 5.683   1 205.9  5352       0          0 293.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2600         0                 4900 1215 31597 26.01\n",
            "\n",
            "00:51:42 | time:196s total_exs:79200 total_steps:4950 epochs:1.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.2     1  1009 25152   .9012      82.17 398.7  800  1.524   .01091 13.12 5.643   1   210  5233       0          0 282.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2594         0                 4950 1219 30385 24.93\n",
            "\n",
            "00:51:44 | time:198s total_exs:80000 total_steps:5000 epochs:1.22\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     140     1  1008 26340   .8888      77.01   418  800  1.527  .009355 12.43 5.682   1 198.9  5195       0          0 293.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2527         0                 5000 1207 31535 26.13\n",
            "\n",
            "00:51:46 | time:200s total_exs:80800 total_steps:5050 epochs:1.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   145.3     1  1009 25936   .8962      82.18 411.2  800   1.52  .009698 12.86 5.666   1 205.7  5287       0          0  289   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2647         0                 5050 1215 31223 25.71\n",
            "\n",
            "00:51:48 | time:202s total_exs:81600 total_steps:5100 epochs:1.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   148.2     1  1010 25674   .8950      85.08 406.8  800  1.524    .0103 13.04 5.682   1 208.6  5304       0          0 293.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2611         0                 5100 1218 30979 25.44\n",
            "\n",
            "00:51:50 | time:204s total_exs:82400 total_steps:5150 epochs:1.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.5     1  1009 26139   .9050      81.42 414.4  800  1.499  .009676 13.11 5.651   1 209.8  5434       0          0 284.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2661         0                 5150 1219 31573 25.91\n",
            "\n",
            "00:51:52 | time:206s total_exs:83200 total_steps:5200 epochs:1.27\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.1     1  1010 26190   .8962      81.95   415  800  1.471  .009681 13.43 5.623   1 214.9  5573       0          0 276.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2685         0                 5200 1225 31763 25.94\n",
            "\n",
            "00:51:54 | time:208s total_exs:84000 total_steps:5250 epochs:1.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.7     1  1012 26730   .9062      82.44 422.6  800  1.516  .009398 13.11 5.616   1 209.7  5539       0          0 274.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2586         0                 5250 1222 32269 26.42\n",
            "\n",
            "00:51:56 | time:210s total_exs:84800 total_steps:5300 epochs:1.29\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   148.2     1  1011 26287   .9113      84.99 415.8  800  1.526   .01032 13.12 5.606   1 209.9  5455       0          0 272.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2682         0                 5300 1221 31742   26\n",
            "\n",
            "00:51:58 | time:212s total_exs:85600 total_steps:5350 epochs:1.30\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.7     1  1010 26166   .9038      81.58 414.6  800  1.511  .009339 12.74 5.653   1 203.8  5282       0          0 285.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2592    .00125                 5350 1214 31448 25.92\n",
            "\n",
            "00:52:00 | time:213s total_exs:86400 total_steps:5400 epochs:1.31\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.5     1  1007 26545   .8888      82.58 421.7  800  1.528  .009664 12.78  5.77   1 204.5  5391       0          0 320.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2465         0                 5400 1212 31936 26.37\n",
            "\n",
            "00:52:01 | time:215s total_exs:87200 total_steps:5450 epochs:1.33\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.2     1  1009 26503   .9025      81.13 420.1  800  1.533   .01003 13.11 5.607   1 209.8  5509       0          0 272.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2660         0                 5450 1219 32012 26.27\n",
            "\n",
            "00:52:03 | time:217s total_exs:88000 total_steps:5500 epochs:1.34\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.9     1  1009 26228   .9038      78.82   416  800  1.489  .009333 13.06 5.561   1   209  5435       0          0 260.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2680         0                 5500 1218 31664 26.01\n",
            "\n",
            "00:52:05 | time:219s total_exs:88800 total_steps:5550 epochs:1.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.1     1  1010 26595   .9062       82.9 421.1  800  1.542   .00966 12.49 5.561   1 199.9  5262       0          0 260.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2585         0                 5550 1210 31857 26.33\n",
            "\n",
            "00:52:07 | time:221s total_exs:89600 total_steps:5600 epochs:1.36\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.6     1  1009 25994   .8912      83.49 412.2  800  1.491  .009358 13.12 5.658   1 209.9  5408       0          0 286.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2603         0                 5600 1219 31403 25.77\n",
            "\n",
            "00:52:09 | time:223s total_exs:90400 total_steps:5650 epochs:1.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.7     1  1010 26459   .9062      80.56   419  800  1.514  .009069 12.82 5.602   1 205.1  5371       0          0 270.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2609         0                 5650 1215 31830 26.2\n",
            "\n",
            "00:52:11 | time:225s total_exs:91200 total_steps:5700 epochs:1.39\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.1     1  1011 26368   .9000      79.95 417.4  800  1.517  .009367 12.85 5.637   1 205.5  5362       0          0 280.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2590         0                 5700 1216 31730 26.1\n",
            "\n",
            "00:52:13 | time:227s total_exs:92000 total_steps:5750 epochs:1.40\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.8     1  1009 26270   .8912      80.79 416.6  800  1.525  .009098 12.83 5.516   1 205.3  5346       0          0 248.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2695         0                 5750 1214 31616 26.05\n",
            "\n",
            "00:52:15 | time:229s total_exs:92800 total_steps:5800 epochs:1.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   149.8     1  1010 25222   .8988      86.65 399.7  800  1.544  .009038 12.81  5.66   1 204.9  5119       0          0 287.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2593         0                 5800 1215 30341 24.99\n",
            "\n",
            "00:52:17 | time:231s total_exs:93600 total_steps:5850 epochs:1.42\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.5     1  1009 25208   .9000      78.39 399.7  800    1.5  .009669 12.92  5.51   1 206.7  5164       0          0 247.1   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2729         0                 5850 1216 30372 24.99\n",
            "\n",
            "00:52:19 | time:233s total_exs:94400 total_steps:5900 epochs:1.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   140.3     1  1009 26347   .8950       77.2 417.7  800  1.504   .01031 12.93 5.623   1 206.9  5401       0          0 276.7   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2692         0                 5900 1216 31748 26.11\n",
            "\n",
            "00:52:21 | time:235s total_exs:95200 total_steps:5950 epochs:1.45\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   140.7     1  1008 24938   .8962      77.69 395.8  800  1.518  .009379 12.47 5.451   1 199.5  4936       0          0  233   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2735    .00125                 5950 1208 29873 24.75\n",
            "\n",
            "00:52:23 | time:237s total_exs:96000 total_steps:6000 epochs:1.46\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   147.8     1  1010 25553   .8975      84.67 404.9  800  1.484   .01065 13.42 5.647   1 214.8  5435       0          0 283.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2578         0                 6000 1225 30987 25.31\n",
            "\n",
            "00:52:25 | time:239s total_exs:96800 total_steps:6050 epochs:1.47\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   145.3     1  1010 26593   .9000      82.21 421.3  800  1.517  .009435 12.73 5.447   1 203.6  5362       0          0  232   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2740         0                 6050 1214 31955 26.34\n",
            "\n",
            "00:52:27 | time:241s total_exs:97600 total_steps:6100 epochs:1.49\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.8     1  1010 26675   .8988      79.64 422.3  800  1.534  .009068  12.5 5.623   1   200  5281       0          0 276.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2575         0                 6100 1211 31956 26.41\n",
            "\n",
            "00:52:29 | time:243s total_exs:98400 total_steps:6150 epochs:1.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.7     1  1009 25987   .8912      81.66 412.2  800  1.509   .01062 12.66 5.578   1 202.6  5219       0          0 264.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2699         0                 6150 1211 31206 25.77\n",
            "\n",
            "00:52:31 | time:245s total_exs:99200 total_steps:6200 epochs:1.51\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.4     1  1012 26433   .9025       82.2   418  800  1.546  .009423 12.62 5.643   1 201.9  5275       0          0 282.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2522    .00125                 6200 1214 31708 26.13\n",
            "\n",
            "00:52:33 | time:247s total_exs:100000 total_steps:6250 epochs:1.52\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.6     1  1009 26037   .9062      79.51 412.9  800  1.526  .009068 12.69  5.58   1 203.1  5242       0          0 265.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2620         0                 6250 1212 31278 25.82\n",
            "\n",
            "00:52:35 | time:249s total_exs:100800 total_steps:6300 epochs:1.53\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.4     1  1011 25821   .8988      81.25 408.7  800  1.495  .009408 12.89 5.444   1 206.3  5269       0          0 231.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2665         0                 6300 1217 31090 25.55\n",
            "\n",
            "00:52:37 | time:251s total_exs:101600 total_steps:6350 epochs:1.55\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.3     1  1007 26212   .8888      76.33 416.5  800  1.558  .009989 12.49 5.553   1 199.9  5204       0          0 257.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2553         0                 6350 1207 31416 26.04\n",
            "\n",
            "00:52:39 | time:253s total_exs:102400 total_steps:6400 epochs:1.56\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.7     1  1009 26292   .8962      82.69 417.1  800  1.487  .009407 13.11  5.57   1 209.7  5466       0          0 262.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2635         0                 6400 1218 31758 26.08\n",
            "\n",
            "00:52:41 | time:254s total_exs:103200 total_steps:6450 epochs:1.57\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.7     1  1009 26305   .9038      81.68 417.2  800   1.53  .009052 12.75  5.56   1   204  5319       0          0 259.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2619         0                 6450 1213 31625 26.09\n",
            "\n",
            "00:52:42 | time:256s total_exs:104000 total_steps:6500 epochs:1.58\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   138.8     1  1009 26440   .8925      75.67 419.1  800  1.528  .009386 12.81 5.543   1   205  5369       0          0 255.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2654         0                 6500 1214 31809 26.2\n",
            "\n",
            "00:52:44 | time:258s total_exs:104800 total_steps:6550 epochs:1.59\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   144.2     1  1010 26392   .9025      81.07 417.9  800  1.556  .009397  12.7 5.565   1 203.1  5306       0          0  261   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2561         0                 6550 1214 31698 26.13\n",
            "\n",
            "00:52:46 | time:260s total_exs:105600 total_steps:6600 epochs:1.61\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.6     1  1011 25587   .9075      83.43 404.9  800  1.524  .009431 12.53 5.449   1 200.5  5074       0          0 232.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2654         0                 6600 1212 30662 25.31\n",
            "\n",
            "00:52:48 | time:262s total_exs:106400 total_steps:6650 epochs:1.62\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   142.2     1  1010 25694   .8950      79.04   407  800  1.517  .009364 12.84 5.447   1 205.4  5226       0          0  232   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2750         0                 6650 1215 30920 25.45\n",
            "\n",
            "00:52:50 | time:264s total_exs:107200 total_steps:6700 epochs:1.63\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     143     1  1009 25747   .8900      79.95 408.1  800   1.51  .009712 12.91 5.539   1 206.6  5271       0          0 254.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2679         0                 6700 1216 31019 25.52\n",
            "\n",
            "00:52:52 | time:266s total_exs:108000 total_steps:6750 epochs:1.64\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.4     1  1011 25407   .9038      82.26 402.1  800  1.502   .01066 13.06 5.424   1   209  5252       0          0 226.8   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2784         0                 6750 1220 30659 25.14\n",
            "\n",
            "00:52:54 | time:268s total_exs:108800 total_steps:6800 epochs:1.66\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.5     1  1012 25981   .9125      83.25 410.8  800  1.538  .009408 12.66 5.574   1 202.5  5201       0          0 263.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2593         0                 6800 1214 31182 25.69\n",
            "\n",
            "00:52:56 | time:270s total_exs:109600 total_steps:6850 epochs:1.67\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.1     1  1012 25596   .9000      82.85 404.8  800  1.485  .009692 13.05 5.527   1 208.8  5283       0          0 251.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2617         0                 6850 1220 30879 25.31\n",
            "\n",
            "00:52:58 | time:272s total_exs:110400 total_steps:6900 epochs:1.68\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     146     1  1010 25494   .9100      82.87   404  800  1.496  .009411 13.23 5.568   1 211.6  5344       0          0 261.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2587         0                 6900 1221 30838 25.26\n",
            "\n",
            "00:53:00 | time:274s total_exs:111200 total_steps:6950 epochs:1.69\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   143.7     1  1010 26383   .9038      80.57   418  800  1.541   .01035 13.27 5.586   1 212.3  5546       0          0 266.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2543         0                 6950 1222 31930 26.14\n",
            "\n",
            "00:53:02 | time:276s total_exs:112000 total_steps:7000 epochs:1.70\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   140.3     1  1008 26149   .9000      77.24 414.9  800  1.525  .009653 12.71 5.506   1 203.3  5271       0          0 246.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2667         0                 7000 1212 31420 25.94\n",
            "\n",
            "00:53:04 | time:278s total_exs:112800 total_steps:7050 epochs:1.72\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     144     1  1010 26239   .9012      80.88 415.8  800  1.519  .009682 12.71 5.585   1 203.3  5282       0          0 266.3   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2562         0                 7050 1213 31522 25.99\n",
            "\n",
            "00:53:06 | time:280s total_exs:113600 total_steps:7100 epochs:1.73\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.9     1  1008 26411   .8962      76.89 419.3  800  1.525  .009373 12.81 5.504   1   205  5374       0          0 245.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2557         0                 7100 1213 31785 26.22\n",
            "\n",
            "00:53:08 | time:282s total_exs:114400 total_steps:7150 epochs:1.74\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "     144     1  1008 26116   .9012         81 414.4  800  1.531  .009403 13.13 5.468   1 210.1  5441       0          0  237   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2641         0                 7150 1218 31557 25.91\n",
            "\n",
            "00:53:10 | time:284s total_exs:115200 total_steps:7200 epochs:1.75\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.8     1  1010 26009   .9000      78.72 412.1  800  1.542  .009104 12.57  5.47   1 201.1  5179       0          0 237.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2689         0                 7200 1211 31188 25.77\n",
            "\n",
            "00:53:12 | time:286s total_exs:116000 total_steps:7250 epochs:1.77\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   144.6     1  1010 26495   .9050      81.45 419.5  800  1.494  .009109 12.94 5.367   1   207  5428       0          0 214.2   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2747         0                 7250 1217 31923 26.23\n",
            "\n",
            "00:53:14 | time:288s total_exs:116800 total_steps:7300 epochs:1.78\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   145.2     1  1010 25906   .8988      82.09 410.5  800   1.52  .009421 13.12 5.484   1   210  5388       0          0 240.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2657    .00125                 7300 1220 31294 25.66\n",
            "\n",
            "00:53:16 | time:290s total_exs:117600 total_steps:7350 epochs:1.79\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "     140     1  1004 25624   .8812      77.22 408.4  800  1.544   .01032 12.92 5.351   1 206.8  5277       0          0 210.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2718         0                 7350 1211 30902 25.53\n",
            "\n",
            "00:53:18 | time:292s total_exs:118400 total_steps:7400 epochs:1.80\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   146.1     1  1011 25807   .9038      82.86 408.3  800  1.491  .009107 13.15 5.377   1 210.4  5370       0          0 216.4   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2722         0                 7400 1222 31178 25.53\n",
            "\n",
            "00:53:20 | time:294s total_exs:119200 total_steps:7450 epochs:1.81\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   139.3     1  1007 25510   .8900      76.35 405.4  800  1.532  .009724 12.76 5.397   1 204.2  5174       0          0 220.6   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2713         0                 7450 1211 30685 25.34\n",
            "\n",
            "00:53:22 | time:296s total_exs:120000 total_steps:7500 epochs:1.83\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   141.8     1  1009 25929   .9038      78.72   411  800  1.525   .01003 12.82 5.642   1 205.1  5270       0          0 281.9   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "        .2534         0                 7500 1214 31199 25.7\n",
            "\n",
            "00:53:24 | time:298s total_exs:120800 total_steps:7550 epochs:1.84\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
            "   142.6     1  1008 26045   .8838      79.67 413.5  800  1.509  .009421 12.82 5.414   1 205.1  5302       0          0 224.5   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2596         0                 7550 1213 31347 25.86\n",
            "\n",
            "00:53:26 | time:300s total_exs:121600 total_steps:7600 epochs:1.85\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
            "   140.8     1  1008 26545   .8900      77.85 421.4  800  1.546  .009686 12.76 5.342   1 204.2  5378       0          0  209   \n",
            "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "        .2793         0                 7600 1212 31924 26.35\n",
            "\n",
            "00:53:26 | max_train_time elapsed:300.03519105911255s\n",
            "00:53:26 | Using CUDA\n",
            "00:53:26 | loading dictionary from from_scratch_model/model.dict\n",
            "00:53:26 | num words = 18745\n",
            "00:53:26 | Total parameters: 2,979,257 (2,979,257 trainable)\n",
            "00:53:26 | Loading existing model params from from_scratch_model/model\n",
            "00:53:26 | creating task(s): personachat\n",
            "00:53:26 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n",
            "00:53:26 | running eval: valid\n",
            "00:54:30 | eval completed in 63.98s\n",
            "00:54:30 | \u001b[1mvalid:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  \\\n",
            "    .0007691 .002546 153.2  1005  7729   .9171      89.78   122 7801 .1476  .000824  13.1 5.307   1 207.8  1598       0   \n",
            "    ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb  tps  \n",
            "            0 201.7      .2853  .0001282                 7612 1213 9327\n",
            "\u001b[0m\n",
            "00:54:30 | creating task(s): personachat\n",
            "00:54:30 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/test_self_original.txt\n",
            "00:54:30 | running eval: test\n",
            "00:55:31 | eval completed in 60.22s\n",
            "00:55:31 | \u001b[1mtest:\n",
            "    accuracy  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  \\\n",
            "    .0006656 .002792 149.6  1002  7891   .9087      86.32 124.8 7512 .1526 .0008732 12.96 5.273   1 205.4  1617       0   \n",
            "    ltrunclen  ppl  token_acc  token_em  total_train_updates  tpb  tps  \n",
            "            0  195      .2929  .0003994                 7612 1208 9508\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': ExactMatchMetric(0.0007691),\n",
              "  'bleu-4': BleuMetric(0.002546),\n",
              "  'clen': AverageMetric(153.2),\n",
              "  'ctpb': GlobalAverageMetric(1005),\n",
              "  'ctps': GlobalTimerMetric(7729),\n",
              "  'ctrunc': AverageMetric(0.9171),\n",
              "  'ctrunclen': AverageMetric(89.78),\n",
              "  'exps': GlobalTimerMetric(122),\n",
              "  'exs': SumMetric(7801),\n",
              "  'f1': F1Metric(0.1476),\n",
              "  'gpu_mem': GlobalAverageMetric(0.000824),\n",
              "  'llen': AverageMetric(13.1),\n",
              "  'loss': AverageMetric(5.307),\n",
              "  'lr': GlobalAverageMetric(1),\n",
              "  'ltpb': GlobalAverageMetric(207.8),\n",
              "  'ltps': GlobalTimerMetric(1598),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(201.7),\n",
              "  'token_acc': AverageMetric(0.2853),\n",
              "  'token_em': AverageMetric(0.0001282),\n",
              "  'total_train_updates': GlobalFixedMetric(7612),\n",
              "  'tpb': GlobalAverageMetric(1213),\n",
              "  'tps': GlobalTimerMetric(9327)},\n",
              " {'accuracy': ExactMatchMetric(0.0006656),\n",
              "  'bleu-4': BleuMetric(0.002792),\n",
              "  'clen': AverageMetric(149.6),\n",
              "  'ctpb': GlobalAverageMetric(1002),\n",
              "  'ctps': GlobalTimerMetric(7891),\n",
              "  'ctrunc': AverageMetric(0.9087),\n",
              "  'ctrunclen': AverageMetric(86.32),\n",
              "  'exps': GlobalTimerMetric(124.8),\n",
              "  'exs': SumMetric(7512),\n",
              "  'f1': F1Metric(0.1526),\n",
              "  'gpu_mem': GlobalAverageMetric(0.0008732),\n",
              "  'llen': AverageMetric(12.96),\n",
              "  'loss': AverageMetric(5.273),\n",
              "  'lr': GlobalAverageMetric(1),\n",
              "  'ltpb': GlobalAverageMetric(205.4),\n",
              "  'ltps': GlobalTimerMetric(1617),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(195),\n",
              "  'token_acc': AverageMetric(0.2929),\n",
              "  'token_em': AverageMetric(0.0003994),\n",
              "  'total_train_updates': GlobalFixedMetric(7612),\n",
              "  'tpb': GlobalAverageMetric(1208),\n",
              "  'tps': GlobalTimerMetric(9508)})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvA77Zwkoviq"
      },
      "source": [
        "Our perplexity and F1 (word overlap) scores are pretty bad, and our BLEU-4 score is nearly 0. That's okay, we would normally want to train for well over an hour. Feel free to change the max_train_time above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QTiTn7aoxv9"
      },
      "source": [
        "## Performance is pretty bad there. Can we improve it?\n",
        "\n",
        "The easiest way to improve it is to *initialize* using a *pretrained model*, utilizing *transfer learning*. Let's use the one from the interactive session at the beginning of the chat!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Jt9bHTn1dP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d592d495-8a8a-43bd-a091-7bf6aa42fe5f"
      },
      "source": [
        "!rm -rf from_pretrained\n",
        "!mkdir -p from_pretrained\n",
        "\n",
        "TrainModel.main(\n",
        "    # similar to before\n",
        "    task='personachat', \n",
        "    model='transformer/generator',\n",
        "    model_file='from_pretrained/model',\n",
        "    \n",
        "    # initialize with a pretrained model\n",
        "    init_model='zoo:tutorial_transformer_generator/model',\n",
        "    \n",
        "    # arguments we get from the pretrained model.\n",
        "    # Unfortunately, these must be looked up separately for each model.\n",
        "    n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n",
        "    label_truncate=128, ffn_size=2048, embedding_size=512,\n",
        "    activation='gelu', variant='xlm',\n",
        "    dict_lower=True, dict_tokenizer='bpe',\n",
        "    dict_file='zoo:tutorial_transformer_generator/model.dict',\n",
        "    learn_positional_embeddings=True,\n",
        "    \n",
        "    # some training arguments, specific to this fine-tuning\n",
        "    # use a small learning rate with ADAM optimizer\n",
        "    lr=1e-5, optimizer='adam',\n",
        "    warmup_updates=100,\n",
        "    # early stopping on perplexity\n",
        "    validation_metric='ppl',\n",
        "    # train at most 10 minutes, and validate every 0.25 epochs\n",
        "    max_train_time=1800, validation_every_n_epochs=0.25,\n",
        "    \n",
        "    # depend on your gpu. If you have a V100, this is good\n",
        "    batchsize=12, fp16=True, fp16_impl='mem_efficient',\n",
        "    \n",
        "    # speeds up validation\n",
        "    skip_generation=True,\n",
        "    \n",
        "    # helps us cram more examples into our gpu at a time\n",
        "    dynamic_batching='full',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00:56:26 | building dictionary first...\n",
            "00:56:26 | No model with opt yet at: from_pretrained/model(.opt)\n",
            "00:56:26 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,download_path: None,loglevel: info,dynamic_batching: full,verbose: False,is_debug: False,datapath: /usr/local/lib/python3.7/dist-packages/data,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,load_from_checkpoint: True,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_length_penalty: 0.65,topk: 10,topp: 0.9,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,compute_tokenized_bleu: False,interactive_mode: False,fp16_impl: mem_efficient,force_fp16_tokens: False,adafactor_eps: (1e-30, 0.001),history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,parlai_home: /usr/local/lib/python3.7/dist-packages\u001b[0m\n",
            "00:56:26 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:new_reddit:presorted --datatype train:stream --numthreads 1 --batchsize 48 --num-epochs 5.0 --max-train-time -1 --validation-every-n-secs 1800.0 --save-after-valid True --validation-every-n-epochs -1 --validation-max-exs 9920 --short-final-eval True --validation-patience 0 --validation-metric-mode min --dict-build-first True --numworkers 4 --pytorch-preprocess False --pytorch-teacher-batch-sort False --batch-sort-cache-type pop --batch-length-range 5 --shuffle False --batch-sort-field text --pytorch-context-length -1 --pytorch-include-labels True --log-every-n-secs 30.0 --distributed-world-size 64 --port 61337 --dropout 0.1 --beam-size 8 --beam-min-n-best 3 --beam-min-length 10 --skip-generation False --inference beam --optimizer fused_adam --learningrate 0.0005 --gradient-clip 10.0 --adam-eps 1e-06 --betas 0.9,0.98 --weight-decay 0.01 --lr-scheduler invsqrt --warmup-updates 20000 --gpu 0 --beam-block-ngram 3 --beam-context-block-ngram 3\u001b[0m\n",
            "00:56:26 | Using CUDA\n",
            "00:56:26 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "00:56:26 | num words = 54944\n",
            "00:56:27 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "00:56:27 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "00:56:28 | \u001b[33mNot loading optim state since optim class changed.\u001b[0m\n",
            "00:56:28 | Opt:\n",
            "00:56:28 |     activation: gelu\n",
            "00:56:28 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "00:56:28 |     adam_eps: 1e-08\n",
            "00:56:28 |     add_p1_after_newln: False\n",
            "00:56:28 |     aggregate_micro: False\n",
            "00:56:28 |     allow_missing_init_opts: False\n",
            "00:56:28 |     attention_dropout: 0.0\n",
            "00:56:28 |     batchsize: 12\n",
            "00:56:28 |     beam_block_full_context: True\n",
            "00:56:28 |     beam_block_list_filename: None\n",
            "00:56:28 |     beam_block_ngram: -1\n",
            "00:56:28 |     beam_context_block_ngram: -1\n",
            "00:56:28 |     beam_delay: 30\n",
            "00:56:28 |     beam_length_penalty: 0.65\n",
            "00:56:28 |     beam_min_length: 1\n",
            "00:56:28 |     beam_size: 1\n",
            "00:56:28 |     betas: '(0.9, 0.999)'\n",
            "00:56:28 |     bpe_add_prefix_space: None\n",
            "00:56:28 |     bpe_debug: False\n",
            "00:56:28 |     bpe_dropout: None\n",
            "00:56:28 |     bpe_merge: None\n",
            "00:56:28 |     bpe_vocab: None\n",
            "00:56:28 |     compute_tokenized_bleu: False\n",
            "00:56:28 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "00:56:28 |     datatype: train\n",
            "00:56:28 |     delimiter: '\\n'\n",
            "00:56:28 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "00:56:28 |     dict_endtoken: __end__\n",
            "00:56:28 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict\n",
            "00:56:28 |     dict_include_test: False\n",
            "00:56:28 |     dict_include_valid: False\n",
            "00:56:28 |     dict_initpath: None\n",
            "00:56:28 |     dict_language: english\n",
            "00:56:28 |     dict_loaded: True\n",
            "00:56:28 |     dict_lower: True\n",
            "00:56:28 |     dict_max_ngram_size: -1\n",
            "00:56:28 |     dict_maxexs: -1\n",
            "00:56:28 |     dict_maxtokens: -1\n",
            "00:56:28 |     dict_minfreq: 0\n",
            "00:56:28 |     dict_nulltoken: __null__\n",
            "00:56:28 |     dict_starttoken: __start__\n",
            "00:56:28 |     dict_textfields: text,labels\n",
            "00:56:28 |     dict_tokenizer: bpe\n",
            "00:56:28 |     dict_unktoken: __unk__\n",
            "00:56:28 |     display_examples: False\n",
            "00:56:28 |     download_path: None\n",
            "00:56:28 |     dropout: 0.0\n",
            "00:56:28 |     dynamic_batching: full\n",
            "00:56:28 |     embedding_projection: random\n",
            "00:56:28 |     embedding_size: 512\n",
            "00:56:28 |     embedding_type: random\n",
            "00:56:28 |     embeddings_scale: True\n",
            "00:56:28 |     eval_batchsize: None\n",
            "00:56:28 |     eval_dynamic_batching: None\n",
            "00:56:28 |     evaltask: None\n",
            "00:56:28 |     ffn_size: 2048\n",
            "00:56:28 |     force_fp16_tokens: False\n",
            "00:56:28 |     fp16: True\n",
            "00:56:28 |     fp16_impl: mem_efficient\n",
            "00:56:28 |     gpu: -1\n",
            "00:56:28 |     gradient_clip: 0.1\n",
            "00:56:28 |     hide_labels: False\n",
            "00:56:28 |     history_add_global_end_token: None\n",
            "00:56:28 |     history_reversed: False\n",
            "00:56:28 |     history_size: -1\n",
            "00:56:28 |     image_cropsize: 224\n",
            "00:56:28 |     image_mode: raw\n",
            "00:56:28 |     image_size: 256\n",
            "00:56:28 |     inference: greedy\n",
            "00:56:28 |     init_model: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model\n",
            "00:56:28 |     init_opt: None\n",
            "00:56:28 |     interactive_mode: False\n",
            "00:56:28 |     invsqrt_lr_decay_gamma: -1\n",
            "00:56:28 |     is_debug: False\n",
            "00:56:28 |     label_truncate: 128\n",
            "00:56:28 |     learn_positional_embeddings: True\n",
            "00:56:28 |     learningrate: 1e-05\n",
            "00:56:28 |     load_from_checkpoint: True\n",
            "00:56:28 |     log_every_n_secs: -1\n",
            "00:56:28 |     log_every_n_steps: 50\n",
            "00:56:28 |     loglevel: info\n",
            "00:56:28 |     lr_scheduler: reduceonplateau\n",
            "00:56:28 |     lr_scheduler_decay: 0.5\n",
            "00:56:28 |     lr_scheduler_patience: 3\n",
            "00:56:28 |     max_train_steps: -1\n",
            "00:56:28 |     max_train_time: 600.0\n",
            "00:56:28 |     metrics: default\n",
            "00:56:28 |     model: transformer/generator\n",
            "00:56:28 |     model_file: from_pretrained/model\n",
            "00:56:28 |     model_parallel: False\n",
            "00:56:28 |     momentum: 0\n",
            "00:56:28 |     multitask_weights: [1]\n",
            "00:56:28 |     mutators: None\n",
            "00:56:28 |     n_decoder_layers: -1\n",
            "00:56:28 |     n_encoder_layers: -1\n",
            "00:56:28 |     n_heads: 16\n",
            "00:56:28 |     n_layers: 8\n",
            "00:56:28 |     n_positions: 512\n",
            "00:56:28 |     n_segments: 0\n",
            "00:56:28 |     nesterov: True\n",
            "00:56:28 |     no_cuda: False\n",
            "00:56:28 |     num_epochs: -1\n",
            "00:56:28 |     num_workers: 0\n",
            "00:56:28 |     nus: (0.7,)\n",
            "00:56:28 |     optimizer: mem_eff_adam\n",
            "00:56:28 |     output_scaling: 1.0\n",
            "00:56:28 |     override: \"{'task': 'personachat', 'model': 'transformer/generator', 'model_file': 'from_pretrained/model', 'init_model': 'zoo:tutorial_transformer_generator/model', 'n_heads': 16, 'n_layers': 8, 'n_positions': 512, 'text_truncate': 512, 'label_truncate': 128, 'ffn_size': 2048, 'embedding_size': 512, 'activation': 'gelu', 'variant': 'xlm', 'dict_lower': True, 'dict_tokenizer': 'bpe', 'dict_file': '/usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model.dict', 'learn_positional_embeddings': True, 'learningrate': 1e-05, 'optimizer': 'adam', 'warmup_updates': 100, 'validation_metric': 'ppl', 'max_train_time': 600.0, 'validation_every_n_epochs': 0.25, 'batchsize': 12, 'fp16': True, 'fp16_impl': 'mem_efficient', 'skip_generation': True, 'dynamic_batching': 'full'}\"\n",
            "00:56:28 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n",
            "00:56:28 |     person_tokens: False\n",
            "00:56:28 |     rank_candidates: False\n",
            "00:56:28 |     relu_dropout: 0.0\n",
            "00:56:28 |     save_after_valid: False\n",
            "00:56:28 |     save_every_n_secs: -1\n",
            "00:56:28 |     share_word_embeddings: True\n",
            "00:56:28 |     short_final_eval: False\n",
            "00:56:28 |     skip_generation: True\n",
            "00:56:28 |     special_tok_lst: None\n",
            "00:56:28 |     split_lines: False\n",
            "00:56:28 |     starttime: May01_00-56\n",
            "00:56:28 |     task: personachat\n",
            "00:56:28 |     temperature: 1.0\n",
            "00:56:28 |     tensorboard_log: False\n",
            "00:56:28 |     tensorboard_logdir: None\n",
            "00:56:28 |     text_truncate: 512\n",
            "00:56:28 |     topk: 10\n",
            "00:56:28 |     topp: 0.9\n",
            "00:56:28 |     truncate: -1\n",
            "00:56:28 |     update_freq: 1\n",
            "00:56:28 |     use_reply: label\n",
            "00:56:28 |     validation_cutoff: 1.0\n",
            "00:56:28 |     validation_every_n_epochs: 0.25\n",
            "00:56:28 |     validation_every_n_secs: -1\n",
            "00:56:28 |     validation_every_n_steps: -1\n",
            "00:56:28 |     validation_max_exs: -1\n",
            "00:56:28 |     validation_metric: ppl\n",
            "00:56:28 |     validation_metric_mode: None\n",
            "00:56:28 |     validation_patience: 10\n",
            "00:56:28 |     validation_share_agent: False\n",
            "00:56:28 |     variant: xlm\n",
            "00:56:28 |     verbose: False\n",
            "00:56:28 |     wandb_entity: None\n",
            "00:56:28 |     wandb_log: False\n",
            "00:56:28 |     wandb_name: None\n",
            "00:56:28 |     wandb_project: None\n",
            "00:56:28 |     warmup_rate: 0.0001\n",
            "00:56:28 |     warmup_updates: 100\n",
            "00:56:28 |     weight_decay: None\n",
            "00:56:29 | creating task(s): personachat\n",
            "00:56:29 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n",
            "00:56:31 | training...\n",
            "00:56:32 | Overflow: setting loss scale to 65536.0\n",
            "00:56:33 | Overflow: setting loss scale to 32768.0\n",
            "00:56:45 | time:13s total_exs:3188 total_steps:50 epochs:0.05\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss        lr  ltpb  ltps  \\\n",
            "   94.39 .9600  6018 23170       0          0 245.5 3188             34079  6.979    .3128 13.54 2.962 5.001e-06 863.3  3324   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps  ups  \n",
            "         0          0 19.35      .3848  .0003137                   50 6881 26493 3.85\n",
            "\n",
            "00:56:58 | time:26s total_exs:5280 total_steps:100 epochs:0.08\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   152.1     1  6364 25216       0          0 165.8 2092             32768  6.858    .3153 13.28 2.879 1e-05 555.5  2201   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 17.81      .4091         0                  100 6920 27417 3.963\n",
            "\n",
            "00:57:10 | time:39s total_exs:7292 total_steps:150 epochs:0.11\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   154.9     1  6232 24238       0          0 156.5 2012             32768  7.203    .3247 12.96 2.796 1e-05 521.7  2029   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 16.37      .4213   .000994                  150 6754 26266 3.889\n",
            "\n",
            "00:57:24 | time:52s total_exs:9420 total_steps:200 epochs:0.14\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   147.6     1  6280 23874       0          0 161.8 2128             32768   6.79    .3413  13.6 2.811 1e-05 578.8  2200   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 16.62      .4212  .0004699                  200 6859 26075 3.802\n",
            "\n",
            "00:57:37 | time:65s total_exs:11572 total_steps:250 epochs:0.18\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   144.4     1  6217 24132       0          0 167.1 2152             32768  6.751    .3261 13.61   2.8 1e-05 585.6  2273   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 16.45      .4259         0                  250 6802 26405 3.882\n",
            "\n",
            "00:57:50 | time:79s total_exs:13660 total_steps:300 epochs:0.21\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   150.6     1  6291 23495       0          0   156 2088             32768  7.037    .3306 13.38 2.721 1e-05 558.7  2087   \n",
            "    ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 15.2      .4352  .0009579                  300 6850 25582 3.735\n",
            "\n",
            "00:58:03 | time:92s total_exs:15716 total_steps:350 epochs:0.24\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   150.8     1  6202 23743       0          0 157.4 2056             32768  6.941    .3401 13.48 2.719 1e-05 554.1  2121   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 15.17      .4357         0                  350 6756 25864 3.829\n",
            "\n",
            "00:58:08 | time:96s total_exs:16472 total_steps:368 epochs:0.25\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   148.7     1  6247 24083       0          0 161.9  756             32768  6.662    .3089  12.9 2.629 1e-05 541.6  2088   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.86      .4408         0                  368 6789 26171 3.856\n",
            "\n",
            "00:58:08 | creating task(s): personachat\n",
            "00:58:08 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n",
            "00:58:09 | running eval: valid\n",
            "00:58:10 | \u001b[33m--skip-generation true produces limited metrics\u001b[0m\n",
            "00:58:26 | eval completed in 16.82s\n",
            "00:58:26 | \u001b[1mvalid:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  \\\n",
            "   156.6  6267 75656       0          0   483 7801   .09013 13.42 2.644 1e-05 537.1  6484       0          0 14.07      .4439   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0007691                  368 6804 82140\n",
            "\u001b[0m\n",
            "00:58:26 | \u001b[1;32mnew best ppl: 14.07\u001b[0m\n",
            "00:58:26 | saving best valid model: from_pretrained/model\n",
            "00:58:26 | Saving dictionary to from_pretrained/model.dict\n",
            "00:58:43 | time:132s total_exs:18672 total_steps:418 epochs:0.28\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   141.2     1  6213 23630       0          0 167.4 2200             32768  6.693    .3263 13.19 2.713 1e-05 580.2  2207   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 15.08      .4352  .0009091                  418 6793 25837 3.804\n",
            "\n",
            "00:58:57 | time:145s total_exs:20784 total_steps:468 epochs:0.32\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   148.9     1  6288 23288       0          0 156.4 2112             32768  6.933    .3365 13.14 2.696 1e-05   555  2055   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 14.83      .4322   .000947                  468 6843 25343 3.704\n",
            "\n",
            "00:59:10 | time:159s total_exs:22888 total_steps:518 epochs:0.35\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   146.8     1  6178 23568       0          0 160.5 2104             32768  6.717    .3153 13.51 2.688 1e-05 568.4  2168   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 14.71      .4375  .0004753                  518 6746 25737 3.815\n",
            "\n",
            "00:59:23 | time:172s total_exs:24804 total_steps:568 epochs:0.38\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "     166     1  6362 23786       0          0 143.3 1916             32768  7.164    .3452 13.29 2.697 1e-05 509.3  1904   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 14.84      .4367  .0005219                  568 6871 25691 3.739\n",
            "\n",
            "00:59:37 | time:185s total_exs:27056 total_steps:618 epochs:0.41\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   138.4     1  6232 23283       0          0 168.3 2252             32768  6.804    .3452 13.18 2.611 1e-05 593.6  2218   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.61      .4467         0                  618 6825 25500 3.737\n",
            "\n",
            "00:59:50 | time:199s total_exs:29176 total_steps:668 epochs:0.44\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "     149     1  6316 23825       0          0 159.9 2120             32768  6.804    .3251 13.35 2.607 1e-05 566.2  2136   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.56      .4469         0                  668 6882 25961 3.773\n",
            "\n",
            "01:00:04 | time:212s total_exs:31384 total_steps:718 epochs:0.48\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "     142     1  6273 22739       0          0 160.1 2208             32768  6.866    .3540 13.12 2.619 1e-05 579.5  2101   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.72      .4443         0                  718 6852 24839 3.625\n",
            "\n",
            "01:00:13 | time:222s total_exs:32904 total_steps:754 epochs:0.50\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   143.4     1  6056 22918       0          0 159.8 1520             32768  6.784    .3263  13.5 2.662 1e-05 569.9  2157   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 14.33      .4330         0                  754 6626 25075 3.786\n",
            "\n",
            "01:00:13 | running eval: valid\n",
            "01:00:30 | eval completed in 16.69s\n",
            "01:00:30 | \u001b[1mvalid:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  \\\n",
            "   156.6  6299 74917       0          0 478.3 7801   .09024 13.42 2.599 1e-05 539.8  6420       0          0 13.45      .4487   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0005128                  754 6839 81338\n",
            "\u001b[0m\n",
            "01:00:30 | \u001b[1;32mnew best ppl: 13.45 (previous best was 14.07)\u001b[0m\n",
            "01:00:30 | saving best valid model: from_pretrained/model\n",
            "01:00:48 | time:257s total_exs:35056 total_steps:804 epochs:0.53\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   146.3     1  6295 22934       0          0 156.8 2152             32768  6.845    .3311 13.08 2.636 1e-05 562.9  2051   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.96      .4427  .0004647                  804 6858 24985 3.643\n",
            "\n",
            "01:01:01 | time:270s total_exs:37144 total_steps:854 epochs:0.57\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   147.7     1  6166 22964       0          0 155.5 2088             32768  6.792    .3153 13.46 2.601 1e-05 562.1  2093   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.47      .4442         0                  854 6728 25057 3.725\n",
            "\n",
            "01:01:15 | time:283s total_exs:39192 total_steps:904 epochs:0.60\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   153.3     1  6279 23341       0          0 152.3 2048             32768   7.03    .3452  13.2 2.612 1e-05 540.8  2010   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.63      .4463         0                  904 6820 25351 3.718\n",
            "\n",
            "01:01:28 | time:297s total_exs:41300 total_steps:954 epochs:0.63\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   147.9     1  6236 23174       0          0 156.7 2108             32768  6.878    .3596 13.15 2.626 1e-05 554.4  2060   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.82      .4383  .0004744                  954 6791 25234 3.716\n",
            "\n",
            "01:01:42 | time:310s total_exs:43416 total_steps:1004 epochs:0.66\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   147.6     1  6247 23203       0          0 157.2 2116             32768  6.714    .3385 13.45  2.61 1e-05 569.3  2114   \n",
            "    ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.6      .4425         0                 1004 6816 25318 3.715\n",
            "\n",
            "01:01:56 | time:324s total_exs:45532 total_steps:1054 epochs:0.69\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   149.4     1  6324 23284       0          0 155.8 2116             32768  6.962    .3365 12.95 2.568 1e-05 548.1  2018   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.04      .4507         0                 1054 6872 25302 3.683\n",
            "\n",
            "01:02:09 | time:338s total_exs:47692 total_steps:1104 epochs:0.73\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   144.8     1  6257 22622       0          0 156.2 2160             32768  6.999    .3723 13.23 2.573 1e-05 571.4  2066   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.11      .4473   .000463                 1104 6829 24688 3.616\n",
            "\n",
            "01:02:20 | time:349s total_exs:49348 total_steps:1144 epochs:0.75\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   147.8     1  6118 22910       0          0   155 1656             32768  6.794    .3247 13.45 2.595 1e-05 556.8  2085   \n",
            "    ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.4      .4487   .001208                 1144 6675 24995 3.745\n",
            "\n",
            "01:02:20 | running eval: valid\n",
            "01:02:37 | eval completed in 17.01s\n",
            "01:02:37 | \u001b[1mvalid:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  \\\n",
            "   156.6  6332 73559       0          0 469.6 7801    .0900 13.42 2.577 1e-05 542.6  6304       0          0 13.16      .4514   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0006409                 1144 6874 79863\n",
            "\u001b[0m\n",
            "01:02:37 | \u001b[1;32mnew best ppl: 13.16 (previous best was 13.45)\u001b[0m\n",
            "01:02:37 | saving best valid model: from_pretrained/model\n",
            "01:02:55 | time:383s total_exs:51280 total_steps:1194 epochs:0.78\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   162.3     1  6273 23216       0          0   143 1932             32768  6.977    .3447 13.21 2.584 1e-05 510.4  1889   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.25      .4508         0                 1194 6783 25105 3.702\n",
            "\n",
            "01:03:08 | time:397s total_exs:53580 total_steps:1244 epochs:0.82\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   135.8     1  6247 23148       0          0 170.5 2300             32768  6.568    .3452  13.3 2.598 1e-05 611.9  2268   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.44      .4468         0                 1244 6859 25416 3.706\n",
            "\n",
            "01:03:22 | time:411s total_exs:55592 total_steps:1294 epochs:0.85\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "     156     1  6276 23174       0          0 148.6 2012             32768  7.043    .3468 13.25 2.594 1e-05 533.2  1969   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.38      .4426         0                 1294 6809 25143 3.693\n",
            "\n",
            "01:03:35 | time:424s total_exs:57708 total_steps:1344 epochs:0.88\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   148.6     1  6287 23439       0          0 157.8 2116             32768  6.765    .3452 13.44 2.612 1e-05 568.6  2120   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.62      .4439         0                 1344 6855 25558 3.729\n",
            "\n",
            "01:03:49 | time:438s total_exs:59788 total_steps:1394 epochs:0.91\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   150.8     1  6275 22606       0          0 149.9 2080             32768  7.018    .3501 13.25 2.587 1e-05 551.3  1986   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.29      .4489         0                 1394 6826 24592 3.603\n",
            "\n",
            "01:04:03 | time:451s total_exs:62072 total_steps:1444 epochs:0.94\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   135.3     1  6182 22907       0          0 169.3 2284             32768  6.598    .3363 13.38  2.58 1e-05 611.4  2266   \n",
            "    ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.2      .4476  .0008757                 1444 6793 25173 3.706\n",
            "\n",
            "01:04:16 | time:465s total_exs:64132 total_steps:1494 epochs:0.98\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   153.2     1  6313 23333       0          0 152.3 2060             32768  7.057    .3641  13.4 2.576 1e-05 551.9  2040   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.14      .4503         0                 1494 6865 25373 3.696\n",
            "\n",
            "01:04:27 | time:475s total_exs:65804 total_steps:1532 epochs:1.00\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   139.7     1  6147 22816       0          0 163.3 1672             32768  6.842    .3891 12.91 2.545 1e-05 567.9  2108   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 12.74      .4554         0                 1532 6714 24924 3.712\n",
            "\n",
            "01:04:27 | running eval: valid\n",
            "01:04:44 | eval completed in 17.11s\n",
            "01:04:44 | \u001b[1mvalid:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  \\\n",
            "   156.6  6267 73093       0          0 466.6 7801   .09004 13.42 2.563 1e-05 537.1  6264       0          0 12.98      .4531   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0007691                 1532 6804 79358\n",
            "\u001b[0m\n",
            "01:04:44 | \u001b[1;32mnew best ppl: 12.98 (previous best was 13.16)\u001b[0m\n",
            "01:04:44 | saving best valid model: from_pretrained/model\n",
            "01:05:02 | time:510s total_exs:67756 total_steps:1582 epochs:1.03\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   162.6     1  6347 23376       0          0 143.8 1952             32768   7.16    .4068 13.25 2.647 1e-05 517.4  1906   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 14.11      .4413         0                 1582 6864 25281 3.684\n",
            "\n",
            "01:05:15 | time:524s total_exs:69856 total_steps:1632 epochs:1.06\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   149.4     1  6276 23069       0          0 154.4 2100             32768  7.107    .3543 13.52 2.607 1e-05 567.8  2087   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.56      .4452         0                 1632 6843 25156 3.676\n",
            "\n",
            "01:05:29 | time:537s total_exs:72108 total_steps:1682 epochs:1.10\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   136.4     1  6143 22759       0          0 166.9 2252             32768  6.589    .3311 13.39 2.544 1e-05 603.2  2235   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 12.73      .4551   .000444                 1682 6746 24994 3.706\n",
            "\n",
            "01:05:43 | time:551s total_exs:74092 total_steps:1732 epochs:1.13\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   159.6     1  6331 22801       0          0 142.9 1984             32768  7.137    .3364 12.94 2.601 1e-05 513.6  1850   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.48      .4480         0                 1732 6845 24650 3.602\n",
            "\n",
            "01:05:56 | time:565s total_exs:76308 total_steps:1782 epochs:1.16\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   141.1     1  6253 23454       0          0 166.3 2216             32768   6.68    .3133 13.33 2.574 1e-05 590.6  2216   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 13.12      .4512  .0004513                 1782 6843 25670 3.752\n",
            "\n",
            "01:06:09 | time:578s total_exs:78488 total_steps:1832 epochs:1.19\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   142.3     1  6206 23104       0          0 162.3 2180             32768  6.773    .3319 12.95 2.547 1e-05 564.7  2102   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 12.77      .4546  .0009174                 1832 6770 25206 3.723\n",
            "\n",
            "01:06:23 | time:592s total_exs:80660 total_steps:1882 epochs:1.23\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  loss    lr  ltpb  ltps  \\\n",
            "   143.4     1  6229 23047       0          0 160.7 2172             32768  6.643    .3453 13.23 2.553 1e-05 574.8  2127   \n",
            "    ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
            "         0          0 12.84      .4557         0                 1882 6804 25174 3.701\n",
            "\n",
            "01:06:31 | max_train_time elapsed:600.0147709846497s\n",
            "01:06:32 | \u001b[33mOverriding opt[\"init_model\"] to zoo:tutorial_transformer_generator/model (previously: /usr/local/lib/python3.7/dist-packages/data/models/tutorial_transformer_generator/model)\u001b[0m\n",
            "01:06:32 | \u001b[33mOverriding opt[\"optimizer\"] to adam (previously: mem_eff_adam)\u001b[0m\n",
            "01:06:32 | \u001b[33myour model is being loaded with opts that do not exist in the model you are initializing the weights with: allow_missing_init_opts: False,loglevel: info,dynamic_batching: full,is_debug: False,eval_dynamic_batching: None,num_workers: 0,max_train_steps: -1,log_every_n_steps: 50,validation_every_n_steps: -1,tensorboard_logdir: None,wandb_log: False,wandb_name: None,wandb_project: None,wandb_entity: None,mutators: None,n_encoder_layers: -1,n_decoder_layers: -1,model_parallel: False,beam_block_full_context: True,beam_length_penalty: 0.65,topk: 10,topp: 0.9,beam_delay: 30,beam_block_list_filename: None,temperature: 1.0,compute_tokenized_bleu: False,fp16_impl: mem_efficient,force_fp16_tokens: True,adafactor_eps: 1e-30,0.001,history_reversed: False,history_add_global_end_token: None,special_tok_lst: None,bpe_vocab: None,bpe_merge: None,bpe_add_prefix_space: None,bpe_dropout: None,invsqrt_lr_decay_gamma: -1,parlai_home: /usr/local/lib/python3.7/dist-packages,dict_loaded: True,download_path: None,verbose: False,datapath: /usr/local/lib/python3.7/dist-packages/data,load_from_checkpoint: True,interactive_mode: False\u001b[0m\n",
            "01:06:32 | \u001b[33myour model is being loaded with opts that differ from the model you are initializing the weights with. Add the following args to your run command to change this: \n",
            "--show-advanced-args False --task internal:new_reddit:presorted --datatype train:stream --numthreads 1 --batchsize 48 --num-epochs 5.0 --max-train-time -1 --validation-every-n-secs 1800.0 --save-after-valid True --validation-every-n-epochs -1 --validation-max-exs 9920 --short-final-eval True --validation-patience 0 --validation-metric-mode min --dict-build-first True --numworkers 4 --pytorch-preprocess False --pytorch-teacher-batch-sort False --batch-sort-cache-type pop --batch-length-range 5 --shuffle False --batch-sort-field text --pytorch-context-length -1 --pytorch-include-labels True --log-every-n-secs 30.0 --distributed-world-size 64 --port 61337 --dropout 0.1 --beam-size 8 --beam-min-n-best 3 --beam-min-length 10 --skip-generation False --inference beam --optimizer fused_adam --learningrate 0.0005 --gradient-clip 10.0 --adam-eps 1e-06 --betas 0.9,0.98 --weight-decay 0.01 --lr-scheduler invsqrt --warmup-updates 20000 --gpu 0 --beam-block-ngram 3 --beam-context-block-ngram 3\u001b[0m\n",
            "01:06:32 | Using CUDA\n",
            "01:06:32 | loading dictionary from from_pretrained/model.dict\n",
            "01:06:32 | num words = 54944\n",
            "01:06:33 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "01:06:33 | Loading existing model params from from_pretrained/model\n",
            "01:06:36 | creating task(s): personachat\n",
            "01:06:36 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n",
            "01:06:38 | running eval: valid\n",
            "01:06:55 | eval completed in 17.11s\n",
            "01:06:55 | \u001b[1mvalid:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  \\\n",
            "   156.6  6235 73292       0          0 467.9 7801   .07869 13.42 2.563 1e-05 534.3  6281       0          0 12.98      .4532   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0007691                 1532 6769 79573\n",
            "\u001b[0m\n",
            "01:06:55 | creating task(s): personachat\n",
            "01:06:55 | loading fbdialog data: /usr/local/lib/python3.7/dist-packages/data/Persona-Chat/personachat/test_self_original.txt\n",
            "01:06:56 | running eval: test\n",
            "01:07:13 | eval completed in 16.07s\n",
            "01:07:13 | \u001b[1mtest:\n",
            "    clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gpu_mem  llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen  ppl  token_acc  \\\n",
            "   153.5  6199 73428       0          0 478.4 7512   .07844 13.32 2.588 1e-05 538.2  6374       0          0 13.3      .4507   \n",
            "    token_em  total_train_updates  tpb   tps  \n",
            "    .0001331                 1532 6737 79802\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'clen': AverageMetric(156.6),\n",
              "  'ctpb': GlobalAverageMetric(6235),\n",
              "  'ctps': GlobalTimerMetric(7.329e+04),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(467.9),\n",
              "  'exs': SumMetric(7801),\n",
              "  'gpu_mem': GlobalAverageMetric(0.07869),\n",
              "  'llen': AverageMetric(13.42),\n",
              "  'loss': AverageMetric(2.563),\n",
              "  'lr': GlobalAverageMetric(1e-05),\n",
              "  'ltpb': GlobalAverageMetric(534.3),\n",
              "  'ltps': GlobalTimerMetric(6281),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(12.98),\n",
              "  'token_acc': AverageMetric(0.4532),\n",
              "  'token_em': AverageMetric(0.0007691),\n",
              "  'total_train_updates': GlobalFixedMetric(1532),\n",
              "  'tpb': GlobalAverageMetric(6769),\n",
              "  'tps': GlobalTimerMetric(7.957e+04)},\n",
              " {'clen': AverageMetric(153.5),\n",
              "  'ctpb': GlobalAverageMetric(6199),\n",
              "  'ctps': GlobalTimerMetric(7.343e+04),\n",
              "  'ctrunc': AverageMetric(0),\n",
              "  'ctrunclen': AverageMetric(0),\n",
              "  'exps': GlobalTimerMetric(478.4),\n",
              "  'exs': SumMetric(7512),\n",
              "  'gpu_mem': GlobalAverageMetric(0.07844),\n",
              "  'llen': AverageMetric(13.32),\n",
              "  'loss': AverageMetric(2.588),\n",
              "  'lr': GlobalAverageMetric(1e-05),\n",
              "  'ltpb': GlobalAverageMetric(538.2),\n",
              "  'ltps': GlobalTimerMetric(6374),\n",
              "  'ltrunc': AverageMetric(0),\n",
              "  'ltrunclen': AverageMetric(0),\n",
              "  'ppl': PPLMetric(13.3),\n",
              "  'token_acc': AverageMetric(0.4507),\n",
              "  'token_em': AverageMetric(0.0001331),\n",
              "  'total_train_updates': GlobalFixedMetric(1532),\n",
              "  'tpb': GlobalAverageMetric(6737),\n",
              "  'tps': GlobalTimerMetric(7.98e+04)})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iBZXTLRvIjb"
      },
      "source": [
        "## Wow that's a lot of options? Where do I find more info?\n",
        "\n",
        "As you might have noticed, there are a LOT of options to ParlAI. You're best reading the [ParlAI docs](https://parl.ai/docs) to find a list of hyperparameters. We provide lists of the command-line args for both models\n",
        "\n",
        "You can get some guidance in this notebook by using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pl8VVl5plfm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "453c1f82-a7ff-4df7-c7ad-f728c6e67854"
      },
      "source": [
        "# note that if you want to see model-specific arguments, you must specify a model name\n",
        "print(TrainModel.help(model='seq2seq'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: TrainModel [-h] [-o INIT_OPT] [-v] [-t TASK]\n",
            "                  [-dt {train,train:stream,train:ordered,train:ordered:stream,train:stream:ordered,train:evalmode,train:evalmode:stream,train:evalmode:ordered,train:evalmode:ordered:stream,train:evalmode:stream:ordered,valid,valid:stream,test,test:stream}]\n",
            "                  [-nt NUMTHREADS] [-bs BATCHSIZE] [-dynb {None,batchsort,full}]\n",
            "                  [-dp DATAPATH] [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL]\n",
            "                  [-et EVALTASK] [-eps NUM_EPOCHS] [-ttim MAX_TRAIN_TIME]\n",
            "                  [-vtim VALIDATION_EVERY_N_SECS] [-stim SAVE_EVERY_N_SECS]\n",
            "                  [-sval SAVE_AFTER_VALID] [-veps VALIDATION_EVERY_N_EPOCHS]\n",
            "                  [-vp VALIDATION_PATIENCE] [-vmt VALIDATION_METRIC]\n",
            "                  [-vmm {max,min}] [-mcs METRICS] [-micro AGGREGATE_MICRO]\n",
            "                  [-tblog TENSORBOARD_LOG] [-hs HIDDENSIZE] [-esz EMBEDDINGSIZE]\n",
            "                  [-nl NUMLAYERS] [-dr DROPOUT] [-bi BIDIRECTIONAL]\n",
            "                  [-att {none,concat,general,dot,local}]\n",
            "                  [-attl ATTENTION_LENGTH] [--attention-time {pre,post}]\n",
            "                  [-rnn {rnn,gru,lstm}] [-dec {same,shared}]\n",
            "                  [-lt {unique,enc_dec,dec_out,all}] [-soft NUMSOFTMAX]\n",
            "                  [-idr INPUT_DROPOUT] [--beam-size BEAM_SIZE]\n",
            "                  [--beam-min-length BEAM_MIN_LENGTH]\n",
            "                  [--beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM]\n",
            "                  [--beam-block-ngram BEAM_BLOCK_NGRAM]\n",
            "                  [--beam-length-penalty BEAM_LENGTH_PENALTY]\n",
            "                  [--inference {topk,beam,nucleus,delayedbeam,greedy}]\n",
            "                  [--topk TOPK] [--topp TOPP] [--beam-delay BEAM_DELAY]\n",
            "                  [--temperature TEMPERATURE]\n",
            "                  [--compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU]\n",
            "                  [-i INTERACTIVE_MODE]\n",
            "                  [-emb {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}]\n",
            "                  [-embp EMBEDDING_PROJECTION] [--fp16 FP16]\n",
            "                  [--fp16-impl {apex,mem_efficient}]\n",
            "                  [-opt {adadelta,adagrad,adam,adamw,sparseadam,adamax,asgd,sgd,rprop,rmsprop,optimizer,lbfgs,mem_eff_adam,adafactor}]\n",
            "                  [-lr LEARNINGRATE] [-clip GRADIENT_CLIP]\n",
            "                  [--adafactor-eps ADAFACTOR_EPS] [-mom MOMENTUM]\n",
            "                  [--nesterov NESTEROV] [-nu NUS] [-beta BETAS]\n",
            "                  [-wdecay WEIGHT_DECAY] [-rc RANK_CANDIDATES] [-tr TRUNCATE]\n",
            "                  [--text-truncate TEXT_TRUNCATE]\n",
            "                  [--label-truncate LABEL_TRUNCATE] [-histsz HISTORY_SIZE]\n",
            "                  [-pt PERSON_TOKENS] [--split-lines SPLIT_LINES]\n",
            "                  [--delimiter DELIMITER] [-gpu GPU | --no-cuda]\n",
            "                  [--bpe-vocab BPE_VOCAB] [--bpe-merge BPE_MERGE]\n",
            "                  [--lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}]\n",
            "                  [--lr-scheduler-patience LR_SCHEDULER_PATIENCE]\n",
            "                  [--lr-scheduler-decay LR_SCHEDULER_DECAY]\n",
            "                  [--max-lr-steps MAX_LR_STEPS]\n",
            "                  [--invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA]\n",
            "\n",
            "Train a model\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "      show this help message and exit\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "      Path to json file of options. Note: Further Command-line arguments\n",
            "      override file-based options. (default: None)\n",
            "  -v, --show-advanced-args\n",
            "      Show hidden command line options (advanced users only) (default: False)\n",
            "  -t, --task TASK\n",
            "      ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n",
            "  -dt, --datatype {train,train:stream,train:ordered,train:ordered:stream,train:stream:ordered,train:evalmode,train:evalmode:stream,train:evalmode:ordered,train:evalmode:ordered:stream,train:evalmode:stream:ordered,valid,valid:stream,test,test:stream}\n",
            "      choose from: train, train:ordered, valid, test. to stream data add\n",
            "      \":stream\" to any option (e.g., train:stream). by default: train is random\n",
            "      with replacement, valid is ordered, test is ordered. (default: train)\n",
            "  -nt, --numthreads NUMTHREADS\n",
            "      number of threads. Used for hogwild if batchsize is 1, else for number of\n",
            "      threads in threadpool loading, (default: 1)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "      batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {None,batchsort,full}\n",
            "      Use dynamic batching (default: None)\n",
            "  -dp, --datapath DATAPATH\n",
            "      path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "      the model class name. can match parlai/agents/<model> for agents in that\n",
            "      directory, or can provide a fully specified module for `from X import Y`\n",
            "      via `-m X:Y` (e.g. `-m parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`)\n",
            "      (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "      model file name for loading and saving models (default: None)\n",
            "  -im, --init-model INIT_MODEL\n",
            "      load model weights and dict from this file (default: None)\n",
            "\n",
            "Training Loop Arguments:\n",
            "  -et, --evaltask EVALTASK\n",
            "      task to use for valid/test (defaults to the one used for training)\n",
            "      (default: None)\n",
            "  -eps, --num-epochs NUM_EPOCHS\n",
            "  -ttim, --max-train-time MAX_TRAIN_TIME\n",
            "  -vtim, --validation-every-n-secs VALIDATION_EVERY_N_SECS\n",
            "      Validate every n seconds. Saves model to model_file (if set) whenever best\n",
            "      val metric is found (default: -1)\n",
            "  -stim, --save-every-n-secs SAVE_EVERY_N_SECS\n",
            "      Saves the model to model_file.checkpoint after every n seconds (default\n",
            "      -1, never). (default: -1)\n",
            "  -sval, --save-after-valid SAVE_AFTER_VALID\n",
            "      Saves the model to model_file.checkpoint after every validation (default\n",
            "      False).\n",
            "  -veps, --validation-every-n-epochs VALIDATION_EVERY_N_EPOCHS\n",
            "      Validate every n epochs. Saves model to model_file (if set) whenever best\n",
            "      val metric is found (default: -1)\n",
            "  -vp, --validation-patience VALIDATION_PATIENCE\n",
            "      number of iterations of validation where result does not improve before we\n",
            "      stop training (default: 10)\n",
            "  -vmt, --validation-metric VALIDATION_METRIC\n",
            "      key into report table for selecting best validation (default: accuracy)\n",
            "  -vmm, --validation-metric-mode {max,min}\n",
            "      how to optimize validation metric (max or min) (default: None)\n",
            "  -mcs, --metrics METRICS\n",
            "      list of metrics to show/compute, e.g. all, default,or give a list split by\n",
            "      , like ppl,f1,accuracy,hits@1,rouge,bleuthe rouge metrics will be computed\n",
            "      as rouge-1, rouge-2 and rouge-l (default: default)\n",
            "  -micro, --aggregate-micro AGGREGATE_MICRO\n",
            "      Report micro-averaged metrics instead of macro averaged metrics. (default:\n",
            "      False)\n",
            "\n",
            "Tensorboard Arguments:\n",
            "  -tblog, --tensorboard-log TENSORBOARD_LOG\n",
            "      Tensorboard logging of metrics, default is False\n",
            "\n",
            "Seq2Seq Arguments:\n",
            "  -hs, --hiddensize HIDDENSIZE\n",
            "      size of the hidden layers (default: 128)\n",
            "  -esz, --embeddingsize EMBEDDINGSIZE\n",
            "      size of the token embeddings (default: 128)\n",
            "  -nl, --numlayers NUMLAYERS\n",
            "      number of hidden layers (default: 2)\n",
            "  -dr, --dropout DROPOUT\n",
            "      dropout rate (default: 0.1)\n",
            "  -bi, --bidirectional BIDIRECTIONAL\n",
            "      whether to encode the context with a bidirectional rnn (default: False)\n",
            "  -att, --attention {none,concat,general,dot,local}\n",
            "      Choices: none, concat, general, local. If set local, also set attention-\n",
            "      length. (see arxiv.org/abs/1508.04025) (default: none)\n",
            "  -attl, --attention-length ATTENTION_LENGTH\n",
            "      Length of local attention. (default: 48)\n",
            "  --attention-time {pre,post}\n",
            "      Whether to apply attention before or after decoding. (default: post)\n",
            "  -rnn, --rnn-class {rnn,gru,lstm}\n",
            "      Choose between different types of RNNs. (default: lstm)\n",
            "  -dec, --decoder {same,shared}\n",
            "      Choose between different decoder modules. Default \"same\" uses same class\n",
            "      as encoder, while \"shared\" also uses the same weights. Note that shared\n",
            "      disabled some encoder options--in particular, bidirectionality. (default:\n",
            "      same)\n",
            "  -lt, --lookuptable {unique,enc_dec,dec_out,all}\n",
            "      The encoder, decoder, and output modules can share weights, or not. Unique\n",
            "      has independent embeddings for each. Enc_dec shares the embedding for the\n",
            "      encoder and decoder. Dec_out shares decoder embedding and output weights.\n",
            "      All shares all three weights. (default: unique)\n",
            "  -soft, --numsoftmax NUMSOFTMAX\n",
            "      default 1, if greater then uses mixture of softmax (see\n",
            "      arxiv.org/abs/1711.03953). (default: 1)\n",
            "  -idr, --input-dropout INPUT_DROPOUT\n",
            "      Probability of replacing tokens with UNK in training. (default: 0.0)\n",
            "\n",
            "Torch Generator Agent:\n",
            "  --beam-size BEAM_SIZE\n",
            "      Beam size, if 1 then greedy search (default: 1)\n",
            "  --beam-min-length BEAM_MIN_LENGTH\n",
            "      Minimum length of prediction to be generated by the beam search (default:\n",
            "      1)\n",
            "  --beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM\n",
            "      Size n-grams to block in beam search from the context. val <= 0 implies no\n",
            "      blocking (default: -1)\n",
            "  --beam-block-ngram BEAM_BLOCK_NGRAM\n",
            "      Size n-grams to block in beam search. val <= 0 implies no blocking\n",
            "      (default: -1)\n",
            "  --beam-length-penalty BEAM_LENGTH_PENALTY\n",
            "      Applies a length penalty. Set to 0 for no penalty. (default: 0.65)\n",
            "  --inference {topk,beam,nucleus,delayedbeam,greedy}\n",
            "      Generation algorithm (default: greedy)\n",
            "  --topk TOPK\n",
            "      K used in Top K sampling (default: 10)\n",
            "  --topp TOPP\n",
            "      p used in nucleus sampling (default: 0.9)\n",
            "  --beam-delay BEAM_DELAY\n",
            "      used in delayedbeam search (default: 30)\n",
            "  --temperature TEMPERATURE\n",
            "      temperature to add during decoding (default: 1.0)\n",
            "  --compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU\n",
            "      if true, compute tokenized bleu scores (default: False)\n",
            "\n",
            "TorchAgent Arguments:\n",
            "  -i, --interactive-mode INTERACTIVE_MODE\n",
            "      Whether in full interactive mode or not, which means generating text or\n",
            "      retrieving from a full set of candidates, which is necessary to actually\n",
            "      do full dialogue. However, during training or quick validation (e.g. PPL\n",
            "      for generation or ranking a few candidates for ranking models) you might\n",
            "      want these set to off. Typically, scripts can set their preferred default\n",
            "      behavior at the start, e.g. eval scripts. (default: False)\n",
            "  -emb, --embedding-type {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}\n",
            "      Choose between different strategies for initializing word embeddings.\n",
            "      Default is random, but can also preinitialize from Glove or Fasttext.\n",
            "      Preinitialized embeddings can also be fixed so they are not updated during\n",
            "      training. (default: random)\n",
            "  -embp, --embedding-projection EMBEDDING_PROJECTION\n",
            "      If pretrained embeddings have a different dimensionality than your\n",
            "      embedding size, strategy for projecting to the correct size. If the\n",
            "      dimensions are the same, this is ignored unless you append \"-force\" to\n",
            "      your choice. (default: random)\n",
            "  --fp16 FP16\n",
            "      Use fp16 computations. (default: False)\n",
            "  --fp16-impl {apex,mem_efficient}\n",
            "      Implementation of FP16 to use (default: apex)\n",
            "  -rc, --rank-candidates RANK_CANDIDATES\n",
            "      Whether the model should parse candidates for ranking. (default: False)\n",
            "  -tr, --truncate TRUNCATE\n",
            "      Truncate input lengths to increase speed / use less memory. (default: -1)\n",
            "  --text-truncate TEXT_TRUNCATE\n",
            "      Text input truncation length: if not specified, this will default to\n",
            "      `truncate` (default: None)\n",
            "  --label-truncate LABEL_TRUNCATE\n",
            "      Label truncation length: if not specified, this will default to `truncate`\n",
            "      (default: None)\n",
            "  -histsz, --history-size HISTORY_SIZE\n",
            "      Number of past dialog utterances to remember. (default: -1)\n",
            "  -pt, --person-tokens PERSON_TOKENS\n",
            "      add person tokens to history. adds __p1__ in front of input text and\n",
            "      __p2__ in front of past labels when available or past utterances generated\n",
            "      by the model. these are added to the dictionary during initialization.\n",
            "      (default: False)\n",
            "  --split-lines SPLIT_LINES\n",
            "      split the dialogue history on newlines and save in separate vectors\n",
            "      (default: False)\n",
            "  --delimiter DELIMITER\n",
            "      Join history lines with this token, defaults to newline (default: )\n",
            "  -gpu, --gpu GPU\n",
            "      which GPU to use (default: -1)\n",
            "  --no-cuda\n",
            "      disable GPUs even if available. otherwise, will use GPUs if available on\n",
            "      the device. (default: False)\n",
            "\n",
            "Optimizer Arguments:\n",
            "  -opt, --optimizer {adadelta,adagrad,adam,adamw,sparseadam,adamax,asgd,sgd,rprop,rmsprop,optimizer,lbfgs,mem_eff_adam,adafactor}\n",
            "      Choose between pytorch optimizers. Any member of torch.optim should be\n",
            "      valid. (default: sgd)\n",
            "  -lr, --learningrate LEARNINGRATE\n",
            "      Learning rate (default: 1)\n",
            "  -clip, --gradient-clip GRADIENT_CLIP\n",
            "      gradient clipping using l2 norm (default: 0.1)\n",
            "  --adafactor-eps ADAFACTOR_EPS\n",
            "      Epsilon values for adafactor optimizer: regularization constants for\n",
            "      square gradient and parameter scale respectively (default: 1e-30,1e-3)\n",
            "  -mom, --momentum MOMENTUM\n",
            "      if applicable, momentum value for optimizer. (default: 0)\n",
            "  --nesterov NESTEROV\n",
            "      if applicable, whether to use nesterov momentum. (default: True)\n",
            "  -nu, --nus NUS\n",
            "      if applicable, nu value(s) for optimizer. can use a single value like 0.7\n",
            "      or a comma-separated tuple like 0.7,1.0 (default: 0.7)\n",
            "  -beta, --betas BETAS\n",
            "      if applicable, beta value(s) for optimizer. can use a single value like\n",
            "      0.9 or a comma-separated tuple like 0.9,0.999 (default: 0.9,0.999)\n",
            "  -wdecay, --weight-decay WEIGHT_DECAY\n",
            "      Weight decay on the weights. (default: None)\n",
            "\n",
            "BPEHelper Arguments:\n",
            "  --bpe-vocab BPE_VOCAB\n",
            "      path to pre-trained tokenizer vocab (default: None)\n",
            "  --bpe-merge BPE_MERGE\n",
            "      path to pre-trained tokenizer merge (default: None)\n",
            "\n",
            "Learning Rate Scheduler:\n",
            "  --lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}\n",
            "      Learning rate scheduler. (default: reduceonplateau)\n",
            "  --lr-scheduler-patience LR_SCHEDULER_PATIENCE\n",
            "      LR scheduler patience. In number of validation runs. If using fixed\n",
            "      scheduler, LR is decayed every <patience> validations. (default: 3)\n",
            "  --lr-scheduler-decay LR_SCHEDULER_DECAY\n",
            "      Decay factor for LR scheduler, or how much LR is multiplied by when it is\n",
            "      lowered. (default: 0.5)\n",
            "  --max-lr-steps MAX_LR_STEPS\n",
            "      Number of train steps the scheduler should take after warmup. Training is\n",
            "      terminated after this many steps. This should only be set for --lr-\n",
            "      scheduler cosine or linear (default: -1)\n",
            "  --invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA\n",
            "      Constant used only to find the lr multiplier for the invsqrt scheduler.\n",
            "      Must be set for --lr-scheduler invsqrt (default: -1)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKGUWyKTwVtX"
      },
      "source": [
        "You'll notice the options are give as commandline arguments. We control our options via `argparse`. The option names are relatively predictable: `--init-model` becomes `init_model`; `--num-epochs` becomes `num_epochs` and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgLwGAq1wZJb"
      },
      "source": [
        "# Looking at model predictions\n",
        "\n",
        "We have shown how we can chat with a model ourselves, interactively. We might want to inspect how the model reacts with a fixed set of inputs. Let's use that model we just trained!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCZgs6OlvJ-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "95b89fa8-22a6-4261-d72e-e82b07517810"
      },
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='personachat',\n",
        "    model_file='from_pretrained/model',\n",
        "    num_examples=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ warning: overriding opt['num_examples'] to 2 (previously: None )]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from from_pretrained/model.dict\n",
            "[ num words =  54944 ]\n",
            "Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "[ Loading existing model params from from_pretrained/model ]\n",
            "[creating task(s): empathetic_dialogues]\n",
            "[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n",
            "\u001b[1;94m    labels: Are you fine now?\u001b[0;0m\n",
            "\u001b[0;95m     model: No response\u001b[0;0m\n",
            "\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Cool :) Is your car damaged a lot?\u001b[0;0m\n",
            "\u001b[0;95m     model: No response\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H3QKTjdwokh"
      },
      "source": [
        "Whoa wait a second! The model isn't giving any responses? That's because we set `--skip-generation true` to speed up training. We need to turn that back off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLiq-vuowamh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "241342eb-6ac6-4a0c-91c5-674ab6b7e0c7"
      },
      "source": [
        "from parlai.scripts.display_model import DisplayModel\n",
        "DisplayModel.main(\n",
        "    task='empathetic_dialogues',\n",
        "    model_file='from_pretrained/model',\n",
        "    num_examples=2,\n",
        "    skip_generation=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ warning: overriding opt['num_examples'] to 2 (previously: None )]\n",
            "[ warning: overriding opt['skip_generation'] to False (previously: True )]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from from_pretrained/model.dict\n",
            "[ num words =  54944 ]\n",
            "Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "[ Loading existing model params from from_pretrained/model ]\n",
            "[creating task(s): empathetic_dialogues]\n",
            "[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n",
            "\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n",
            "\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n",
            "\u001b[1;94m    labels: Are you fine now?\u001b[0;0m\n",
            "\u001b[0;95m     model: oh no ! that ' s terrible ! did you get a new tire ?\u001b[0;0m\n",
            "\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n",
            "\u001b[1;94m    labels: Cool :) Is your car damaged a lot?\u001b[0;0m\n",
            "\u001b[0;95m     model: that ' s good . i hope you are okay .\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MR0rn0ZwyxQ"
      },
      "source": [
        "On the command line:\n",
        "```bash\n",
        "python -m parlai.scripts.display_model --task empathetic_dialogues --model-file zoo:tutorial_transformer_generator/model\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYuaSPWrw0Il"
      },
      "source": [
        "# Bringing your own datasets\n",
        "\n",
        "What if you want to build your own dataset in ParlAI? Of course you can do that!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SgJi8XHwtph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9656b678-9dfc-4cfa-d1eb-3cb13aa14608"
      },
      "source": [
        "from parlai.core.teachers import register_teacher, DialogTeacher\n",
        "\n",
        "@register_teacher(\"my_teacher\")\n",
        "class MyTeacher(DialogTeacher):\n",
        "    def __init__(self, opt, shared=None):\n",
        "        # opt is the command line arguments.\n",
        "        \n",
        "        # What is this shared thing?\n",
        "        # We make many copies of a teacher, one-per-batchsize. Shared lets us store \n",
        "        \n",
        "        # We just need to set the \"datafile\".  This is boilerplate, but differs in many teachers.\n",
        "        # The \"datafile\" is the filename where we will load the data from. In this case, we'll set it to\n",
        "        # the fold name (train/valid/test) + \".txt\"\n",
        "        opt['datafile'] = opt['datatype'].split(':')[0] + \".txt\"\n",
        "        super().__init__(opt, shared)\n",
        "    \n",
        "    def setup_data(self, datafile):\n",
        "        # filename tells us where to load from.\n",
        "        # We'll just use some hardcoded data, but show how you could read the filename here:\n",
        "        print(f\" ~~ Loading from {datafile} ~~ \")\n",
        "        \n",
        "        # setup_data should yield tuples of ((text, label), new_episode)\n",
        "        # That is ((str, str), bool)\n",
        "        \n",
        "        # first episode\n",
        "        # notice how we have call, response, and then True? The True indicates this is a first message\n",
        "        # in a conversation\n",
        "        yield ('Hello', 'Hi'), True\n",
        "        # Next we have the second turn. This time, the last element is False, indicating we're still going\n",
        "        yield ('How are you', 'I am fine'), False\n",
        "        yield (\"Let's say goodbye\", 'Goodbye!'), False\n",
        "        \n",
        "        # second episode. We need to have True again!\n",
        "        yield (\"Hey\", \"hi there\"), True\n",
        "        yield (\"Deja vu?\", \"Deja vu!\"), False\n",
        "        yield (\"Last chance\", \"This is it\"), False\n",
        "        \n",
        "        \n",
        "DisplayData.main(task=\"my_teacher\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from train.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher - - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "   \u001b[1;94mHi\u001b[0;0m\n",
            "\u001b[0mHow are you\u001b[0;0m\n",
            "   \u001b[1;94mI am fine\u001b[0;0m\n",
            "\u001b[0mLet's say goodbye\u001b[0;0m\n",
            "   \u001b[1;94mGoodbye!\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher - - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "   \u001b[1;94mhi there\u001b[0;0m\n",
            "\u001b[0mDeja vu?\u001b[0;0m\n",
            "   \u001b[1;94mDeja vu!\u001b[0;0m\n",
            "\u001b[0mLast chance\u001b[0;0m\n",
            "   \u001b[1;94mThis is it\u001b[0;0m\n",
            "EPOCH DONE\n",
            "[ loaded 2 episodes with a total of 6 examples ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvwxi6gXw8jU"
      },
      "source": [
        "Notice how the data corresponds to the utterances we provided? In reality, we'd normally want to load up a data file, loop through it, and yield the tuples from processed data. But for this simple example, it works well.\n",
        "\n",
        "We can now use our teacher in the standard places! Let's see how the model we trained earlier behaves with it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIyZQnxAw5HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "7240d04f-f9d3-4188-9bc8-c67f99b873b5"
      },
      "source": [
        "DisplayModel.main(task='my_teacher', model_file='from_pretrained/model', skip_generation=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ warning: overriding opt['task'] to my_teacher (previously: empathetic_dialogues )]\n",
            "[ warning: overriding opt['skip_generation'] to False (previously: True )]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from from_pretrained/model.dict\n",
            "[ num words =  54944 ]\n",
            "Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "[ Loading existing model params from from_pretrained/model ]\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from valid.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: hi\u001b[0;0m\n",
            "\u001b[0mHow are you\u001b[0;0m\n",
            "\u001b[1;94m    labels: I am fine\u001b[0;0m\n",
            "\u001b[0;95m     model: i am good , how are you ?\u001b[0;0m\n",
            "\u001b[0mLet's say goodbye\u001b[0;0m\n",
            "\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n",
            "\u001b[0;95m     model: i am fine\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi there\u001b[0;0m\n",
            "\u001b[0;95m     model: hi\u001b[0;0m\n",
            "\u001b[0mDeja vu?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' ve just been in this place before\u001b[0;0m\n",
            "\u001b[0mLast chance\u001b[0;0m\n",
            "\u001b[1;94m    labels: This is it\u001b[0;0m\n",
            "\u001b[0;95m     model: i ' ve just been in this place before\u001b[0;0m\n",
            "EPOCH DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOzvSHAy0meK"
      },
      "source": [
        "Note that the `register_teacher` decorator makes the commands aware of your teacher. If you leave it off, the commands won't be able to locate it. If you want to use your teacher on the command line, you'll need to put it in a very specific filename: `parlai/agents/my_teacher/agents.py`, and you'll need to name the class `DefaultTeacher` instead of `MyTeacher`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJj7Lhs00oOB"
      },
      "source": [
        "# Creating your own models\n",
        "\n",
        "As a start, we'll implement a *very* simple agent. This agent will just sort of respond with \"hello X, my name is Y\", where X is based on the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pykhtFDrxCPo"
      },
      "source": [
        "from parlai.core.agents import register_agent, Agent\n",
        "\n",
        "@register_agent(\"hello\")\n",
        "class HelloAgent(Agent):\n",
        "    @classmethod\n",
        "    def add_cmdline_args(cls, parser):\n",
        "        parser.add_argument('--name', type=str, default='Alice', help=\"The agent's name.\")\n",
        "        return parser\n",
        "        \n",
        "    def __init__(self, opt, shared=None):\n",
        "        # similar to the teacher, we have the Opt and the shared memory objects!\n",
        "        super().__init__(opt, shared)\n",
        "        self.id = 'HelloAgent'\n",
        "        self.name = opt['name']\n",
        "    \n",
        "    def observe(self, observation):\n",
        "        # Gather the last word from the other user's input\n",
        "        words = observation.get('text', '').split()\n",
        "        if words:\n",
        "            self.last_word = words[-1]\n",
        "        else:\n",
        "            self.last_word = \"stranger!\"\n",
        "    \n",
        "    def act(self):\n",
        "        # Always return a string like this.\n",
        "        return {\n",
        "            'id': self.id,\n",
        "            'text': f\"Hello {self.last_word}, I'm {self.name}\",\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1SZmy_s0sGd"
      },
      "source": [
        "Let's try seeing how this agent behaves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcS1UIFH0pb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "bcc52fbf-49f8-47ed-e5db-09e5b6c57b54"
      },
      "source": [
        "DisplayModel.main(task='my_teacher', model='hello')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from valid.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello Hello, I'm Alice\u001b[0;0m\n",
            "\u001b[0mHow are you\u001b[0;0m\n",
            "\u001b[1;94m    labels: I am fine\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello you, I'm Alice\u001b[0;0m\n",
            "\u001b[0mLet's say goodbye\u001b[0;0m\n",
            "\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello goodbye, I'm Alice\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi there\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello Hey, I'm Alice\u001b[0;0m\n",
            "\u001b[0mDeja vu?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello vu?, I'm Alice\u001b[0;0m\n",
            "\u001b[0mLast chance\u001b[0;0m\n",
            "\u001b[1;94m    labels: This is it\u001b[0;0m\n",
            "\u001b[0;95m     model: Hello chance, I'm Alice\u001b[0;0m\n",
            "EPOCH DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmvcRSGS0wQE"
      },
      "source": [
        "Notice how it read the words from the user, and provides its name from the command line argument? We can also interact with it easily enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xd5CaG00tv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "4d9aee8c-d390-46c7-e685-febcd5a5b91c"
      },
      "source": [
        "Interactive.main(model='hello', name='Bob')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ optional arguments: ] \n",
            "[  display_examples: False ]\n",
            "[  display_ignore_fields: label_candidates,text_candidates ]\n",
            "[  display_prettify: False ]\n",
            "[  interactive_task: True ]\n",
            "[  name: Bob ]\n",
            "[ Main ParlAI Arguments: ] \n",
            "[  batchsize: 1 ]\n",
            "[  datapath: /usr/local/lib/python3.6/dist-packages/data ]\n",
            "[  datatype: train ]\n",
            "[  download_path: /usr/local/lib/python3.6/dist-packages/downloads ]\n",
            "[  dynamic_batching: None ]\n",
            "[  hide_labels: False ]\n",
            "[  image_mode: raw ]\n",
            "[  init_opt: None ]\n",
            "[  multitask_weights: [1] ]\n",
            "[  numthreads: 1 ]\n",
            "[  show_advanced_args: False ]\n",
            "[  task: interactive ]\n",
            "[ ParlAI Model Arguments: ] \n",
            "[  dict_class: None ]\n",
            "[  init_model: None ]\n",
            "[  model: hello ]\n",
            "[  model_file: None ]\n",
            "[ Local Human Arguments: ] \n",
            "[  local_human_candidates_file: None ]\n",
            "[  single_turn: False ]\n",
            "[ ParlAI Image Preprocessing Arguments: ] \n",
            "[  image_cropsize: 224 ]\n",
            "[  image_size: 256 ]\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "[creating task(s): interactive]\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m hi, who are you?\n",
            "\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello you?, I'm Bob\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m My name is Stephen\n",
            "\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello Stephen, I'm Bob\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello stranger!, I'm Bob\u001b[0;0m\n",
            "CHAT DONE \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAe1hytf1BPk"
      },
      "source": [
        "Similar to the teacher, the call to `register_agent` makes it available for use in commands. If you forget the `register_agent` decorator, you won't be able to refer to it. Similarly, if you wanted to use this model from the command line, you would need to save this code to a special folder: `parlai/agents/hello/hello.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aBbhKTO1DEE"
      },
      "source": [
        "## Creating a neural network model\n",
        "\n",
        "The base Agent class is very simple, but it also provides extremely little functionality. We have created solid abstractions for creating neural-network type models. [`TorchGeneratorAgent`](https://parl.ai/docs/torch_agent.html#module-parlai.core.torch_generator_agent) is one our common abstractions, and it assumes a model which outputs one-word-at-a-time.\n",
        "\n",
        "The following is from our [ExampleSeq2Seq](https://github.com/facebookresearch/ParlAI/blob/master/parlai/agents/examples/seq2seq.py) agent. It's a simple RNN model, trained like a Machine Translation model. The Model is too complex to go over in this document, but please feel free to [read our TorchGeneratorAgent tutorial](https://parl.ai/docs/tutorial_torch_generator_agent.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrZh-T903wh"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import parlai.core.torch_generator_agent as tga\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Example encoder, consisting of an embedding layer and a 1-layer LSTM with the\n",
        "    specified hidden size.\n",
        "    Pay particular attention to the ``forward`` output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embeddings, hidden_size):\n",
        "        \"\"\"\n",
        "        Initialization.\n",
        "        Arguments here can be used to provide hyperparameters.\n",
        "        \"\"\"\n",
        "        # must call super on all nn.Modules.\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = embeddings\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, input_tokens):\n",
        "        \"\"\"\n",
        "        Perform the forward pass for the encoder.\n",
        "        Input *must* be input_tokens, which are the context tokens given\n",
        "        as a matrix of lookup IDs.\n",
        "        :param input_tokens:\n",
        "            Input tokens as a bsz x seqlen LongTensor.\n",
        "            Likely will contain padding.\n",
        "        :return:\n",
        "            You can return anything you like; it is will be passed verbatim\n",
        "            into the decoder for conditioning. However, it should be something\n",
        "            you can easily manipulate in ``reorder_encoder_states``.\n",
        "            This particular implementation returns the hidden and cell states from the\n",
        "            LSTM.\n",
        "        \"\"\"\n",
        "        embedded = self.embeddings(input_tokens)\n",
        "        _output, hidden = self.lstm(embedded)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic example decoder, consisting of an embedding layer and a 1-layer LSTM with the\n",
        "    specified hidden size. Decoder allows for incremental decoding by ingesting the\n",
        "    current incremental state on each forward pass.\n",
        "    Pay particular note to the ``forward``.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embeddings, hidden_size):\n",
        "        \"\"\"\n",
        "        Initialization.\n",
        "        Arguments here can be used to provide hyperparameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embeddings = embeddings\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "    def forward(self, input, encoder_state, incr_state=None):\n",
        "        \"\"\"\n",
        "        Run forward pass.\n",
        "        :param input:\n",
        "            The currently generated tokens from the decoder.\n",
        "        :param encoder_state:\n",
        "            The output from the encoder module.\n",
        "        :parm incr_state:\n",
        "            The previous hidden state of the decoder.\n",
        "        \"\"\"\n",
        "        embedded = self.embeddings(input)\n",
        "        if incr_state is None:\n",
        "            # this is our very first call. We want to seed the LSTM with the\n",
        "            # hidden state of the decoder\n",
        "            state = encoder_state\n",
        "        else:\n",
        "            # We've generated some tokens already, so we can reuse the existing\n",
        "            # decoder state\n",
        "            state = incr_state\n",
        "\n",
        "        # get the new output and decoder incremental state\n",
        "        output, incr_state = self.lstm(embedded, state)\n",
        "\n",
        "        return output, incr_state\n",
        "\n",
        "\n",
        "class ExampleModel(tga.TorchGeneratorModel):\n",
        "    \"\"\"\n",
        "    ExampleModel implements the abstract methods of TorchGeneratorModel to define how to\n",
        "    re-order encoder states and decoder incremental states.\n",
        "    It also instantiates the embedding table, encoder, and decoder, and defines the\n",
        "    final output layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dictionary, hidden_size=1024):\n",
        "        super().__init__(\n",
        "            padding_idx=dictionary[dictionary.null_token],\n",
        "            start_idx=dictionary[dictionary.start_token],\n",
        "            end_idx=dictionary[dictionary.end_token],\n",
        "            unknown_idx=dictionary[dictionary.unk_token],\n",
        "        )\n",
        "        self.embeddings = nn.Embedding(len(dictionary), hidden_size)\n",
        "        self.encoder = Encoder(self.embeddings, hidden_size)\n",
        "        self.decoder = Decoder(self.embeddings, hidden_size)\n",
        "\n",
        "    def output(self, decoder_output):\n",
        "        \"\"\"\n",
        "        Perform the final output -> logits transformation.\n",
        "        \"\"\"\n",
        "        return F.linear(decoder_output, self.embeddings.weight)\n",
        "\n",
        "    def reorder_encoder_states(self, encoder_states, indices):\n",
        "        \"\"\"\n",
        "        Reorder the encoder states to select only the given batch indices.\n",
        "        Since encoder_state can be arbitrary, you must implement this yourself.\n",
        "        Typically you will just want to index select on the batch dimension.\n",
        "        \"\"\"\n",
        "        h, c = encoder_states\n",
        "        return h[:, indices, :], c[:, indices, :]\n",
        "\n",
        "    def reorder_decoder_incremental_state(self, incr_state, indices):\n",
        "        \"\"\"\n",
        "        Reorder the decoder states to select only the given batch indices.\n",
        "        This method can be a stub which always returns None; this will result in the\n",
        "        decoder doing a complete forward pass for every single token, making generation\n",
        "        O(n^2). However, if any state can be cached, then this method should be\n",
        "        implemented to reduce the generation complexity to O(n).\n",
        "        \"\"\"\n",
        "        h, c = incr_state\n",
        "        return h[:, indices, :], c[:, indices, :]\n",
        "\n",
        "\n",
        "@register_agent(\"my_first_lstm\")\n",
        "class Seq2seqAgent(tga.TorchGeneratorAgent):\n",
        "    \"\"\"\n",
        "    Example agent.\n",
        "    Implements the interface for TorchGeneratorAgent. The minimum requirement is that it\n",
        "    implements ``build_model``, but we will want to include additional command line\n",
        "    parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def add_cmdline_args(cls, argparser):\n",
        "        \"\"\"\n",
        "        Add CLI arguments.\n",
        "        \"\"\"\n",
        "        # Make sure to add all of TorchGeneratorAgent's arguments\n",
        "        super(Seq2seqAgent, cls).add_cmdline_args(argparser)\n",
        "\n",
        "        # Add custom arguments only for this model.\n",
        "        group = argparser.add_argument_group('Example TGA Agent')\n",
        "        group.add_argument(\n",
        "            '-hid', '--hidden-size', type=int, default=1024, help='Hidden size.'\n",
        "        )\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"\n",
        "        Construct the model.\n",
        "        \"\"\"\n",
        "\n",
        "        model = ExampleModel(self.dict, self.opt['hidden_size'])\n",
        "        # Optionally initialize pre-trained embeddings by copying them from another\n",
        "        # source: GloVe, fastText, etc.\n",
        "        self._copy_embeddings(model.embeddings.weight, self.opt['embedding_type'])\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfR9w_Hm1HHY"
      },
      "source": [
        "Of course, now we can train with our new model. Let's train it on our toy task that we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJMXpogz1E-_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "3fe8275b-a7cd-491a-a761-fbd5849e2a7c"
      },
      "source": [
        "# of course, we can train the model! Let's Train it on our silly toy task from above\n",
        "!rm -rf my_first_lstm\n",
        "!mkdir -p my_first_lstm\n",
        "\n",
        "TrainModel.main(\n",
        "    model='my_first_lstm',\n",
        "    model_file='my_first_lstm/model',\n",
        "    task='my_teacher',\n",
        "    batchsize=1,\n",
        "    validation_every_n_secs=10,\n",
        "    max_train_time=60,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building dictionary: 100%|██████████| 6.00/6.00 [00:00<00:00, 1.91kex/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ building dictionary first... ]\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from train.txt ~~ \n",
            " ~~ Loading from train.txt ~~ \n",
            "Dictionary: saving dictionary to my_first_lstm/model.dict\n",
            "[ dictionary built with 30 tokens in 0s ]\n",
            "[ no model with opt yet at: my_first_lstm/model(.opt) ]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from my_first_lstm/model.dict\n",
            "[ num words =  30 ]\n",
            "Total parameters: 16,824,320 (16,824,320 trainable)\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from train.txt ~~ \n",
            "[ training... ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ time:10.0s total_exs:1828 epochs:304.67 ]\n",
            "     clip  exs  gnorm  gpu_mem   loss  lr   ppl  token_acc  total_train_updates   tpb  updates\n",
            "   .01641 1828  1.368    .9171 .04105   1 1.042      .9942                 1828 3.328     1828\n",
            "\n",
            "[ time:10.0s total_exs:1828 epochs:304.67 ]\n",
            "    gpu_mem  lr  total_train_updates\n",
            "      .9171   1                 1828\n",
            "\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from valid.txt ~~ \n",
            "[ running eval: valid ]\n",
            "[ eval completed in 0.06s ]\n",
            "valid:\n",
            "    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n",
            "           1 .0003337    6   1    .9171     0   1    1          1                 1828 3.333\n",
            "\n",
            "[ new best accuracy: 1 ]\n",
            "[ saving best valid model: my_first_lstm/model ]\n",
            "[ task solved! stopping. ]\n",
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from my_first_lstm/model.dict\n",
            "[ num words =  30 ]\n",
            "Total parameters: 16,824,320 (16,824,320 trainable)\n",
            "[ Loading existing model params from my_first_lstm/model ]\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from valid.txt ~~ \n",
            "[ running eval: valid ]\n",
            "[ eval completed in 0.05s ]\n",
            "valid:\n",
            "    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n",
            "           1 .0003337    6   1    .9131     0   1    1          1                 1828 3.333\n",
            "\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from test.txt ~~ \n",
            "[ running eval: test ]\n",
            "[ eval completed in 0.05s ]\n",
            "test:\n",
            "    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n",
            "           1 .0003337    6   1    .9131     0   1    1          1                 1828 3.333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHrruVd1KnK"
      },
      "source": [
        "Let's see how it does. It should reproduce the data perfectly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shqFpdrE1Iif",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "1a89571c-2a42-48b8-9752-dffc4a58e557"
      },
      "source": [
        "DisplayModel.main(model_file='my_first_lstm/model', task='my_teacher')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ Using CUDA ]\n",
            "Dictionary: loading dictionary from my_first_lstm/model.dict\n",
            "[ num words =  30 ]\n",
            "Total parameters: 16,824,320 (16,824,320 trainable)\n",
            "[ Loading existing model params from my_first_lstm/model ]\n",
            "[creating task(s): my_teacher]\n",
            " ~~ Loading from valid.txt ~~ \n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHello\u001b[0;0m\n",
            "\u001b[1;94m    labels: Hi\u001b[0;0m\n",
            "\u001b[0;95m     model: Hi\u001b[0;0m\n",
            "\u001b[0mHow are you\u001b[0;0m\n",
            "\u001b[1;94m    labels: I am fine\u001b[0;0m\n",
            "\u001b[0;95m     model: I am fine\u001b[0;0m\n",
            "\u001b[0mLet's say goodbye\u001b[0;0m\n",
            "\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n",
            "\u001b[0;95m     model: Goodbye !\u001b[0;0m\n",
            "\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n",
            "\u001b[0mHey\u001b[0;0m\n",
            "\u001b[1;94m    labels: hi there\u001b[0;0m\n",
            "\u001b[0;95m     model: hi there\u001b[0;0m\n",
            "\u001b[0mDeja vu?\u001b[0;0m\n",
            "\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n",
            "\u001b[0;95m     model: Deja vu !\u001b[0;0m\n",
            "\u001b[0mLast chance\u001b[0;0m\n",
            "\u001b[1;94m    labels: This is it\u001b[0;0m\n",
            "\u001b[0;95m     model: This is it\u001b[0;0m\n",
            "EPOCH DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hzrDhPS1QCW"
      },
      "source": [
        "Unsurprisingly, we got perfect accuracy. This is because the data set is only a handful of utterances, and we can perfectly memorize it in this LSTM. Nonetheless, a great success!\n",
        "\n",
        "# What's next!\n",
        "\n",
        "The sky's the limit! Be sure to check out our [GitHub](https://github.com/facebookresearch/ParlAI) and [Follow ParlAI on Twitter](https://twitter.com/parlai_parley). We're eager to hear what you are using ParlAI for!\n",
        "\n",
        "Here are some other great resources:\n",
        "- [Our research page](https://parl.ai/projects/)\n",
        "- [ParlAI Documentations](https://parl.ai/docs/index.html)\n",
        "- [Tutorial: Writing a Ranker model](https://parl.ai/docs/tutorial_torch_ranker_agent.html)\n",
        "- [Tutorial: Using Mechanical Turk](https://parl.ai/docs/tutorial_mturk.html)\n",
        "- [Tutorial: Connecting to chat services](https://parl.ai/docs/tutorial_chat_service.html)"
      ]
    }
  ]
}